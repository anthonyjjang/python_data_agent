#!/usr/bin/env python3
"""
Ollama ì„¤ì¹˜ ë° ì—°ê²° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import requests
import json
import subprocess
import sys

def check_ollama_installed():
    """Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    try:
        result = subprocess.run(['ollama', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… Ollama ì„¤ì¹˜ë¨: {result.stdout.strip()}")
            return True
        else:
            print("âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
    except FileNotFoundError:
        print("âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

def check_ollama_server():
    """Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            print("âœ… Ollama ì„œë²„ ì‹¤í–‰ ì¤‘")
            return True
        else:
            print(f"âŒ Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    except Exception as e:
        print(f"âŒ Ollama ì„œë²„ í™•ì¸ ì‹¤íŒ¨: {e}")
        return False

def get_installed_models():
    """ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            if models:
                print("ğŸ“¦ ì„¤ì¹˜ëœ ëª¨ë¸:")
                for model in models:
                    name = model.get("name", "Unknown")
                    size = model.get("size", 0)
                    size_gb = size / (1024**3) if size > 0 else 0
                    print(f"   - {name} ({size_gb:.1f}GB)")
                return [model["name"] for model in models]
            else:
                print("ğŸ“¦ ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []
        else:
            print("âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨")
            return []
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return []

def test_model(model_name):
    """íŠ¹ì • ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸: {model_name}")
    
    url = "http://localhost:11434/api/generate"
    headers = {"Content-Type": "application/json"}
    payload = {
        "model": model_name,
        "prompt": "ì•ˆë…•í•˜ì„¸ìš”. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤. 'í…ŒìŠ¤íŠ¸ ì„±ê³µ'ì´ë¼ê³  í•œêµ­ì–´ë¡œ ë‹µí•´ì£¼ì„¸ìš”.",
        "stream": False
    }
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
        if response.status_code == 200:
            result = response.json()
            response_text = result.get("response", "")
            print(f"âœ… {model_name} í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            print(f"ğŸ“ ì‘ë‹µ: {response_text[:100]}...")
            return True
        else:
            print(f"âŒ {model_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: HTTP {response.status_code}")
            print(f"   ì˜¤ë¥˜: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ {model_name} í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return False

def install_recommended_model():
    """ê¶Œì¥ ëª¨ë¸ ì„¤ì¹˜"""
    print("\nğŸ“¥ ê¶Œì¥ ëª¨ë¸ ì„¤ì¹˜ ì¤‘...")
    recommended_model = "qwen2.5:3b"
    
    try:
        print(f"ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {recommended_model}")
        print("â³ ë‹¤ìš´ë¡œë“œì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
        
        result = subprocess.run(['ollama', 'pull', recommended_model], 
                              capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print(f"âœ… {recommended_model} ì„¤ì¹˜ ì™„ë£Œ!")
            return True
        else:
            print(f"âŒ ëª¨ë¸ ì„¤ì¹˜ ì‹¤íŒ¨: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print("âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
        return False
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì„¤ì¹˜ ì˜¤ë¥˜: {e}")
        return False

def main():
    print("ğŸ¦™ Ollama ì„¤ì¹˜ ë° ì—°ê²° í…ŒìŠ¤íŠ¸")
    print("=" * 40)
    
    # 1. Ollama ì„¤ì¹˜ í™•ì¸
    if not check_ollama_installed():
        print("\nğŸ’¡ Ollama ì„¤ì¹˜ ë°©ë²•:")
        print("   macOS: brew install ollama")
        print("   ê¸°íƒ€: https://ollama.ai/download")
        return
    
    # 2. ì„œë²„ ì‹¤í–‰ í™•ì¸
    if not check_ollama_server():
        print("\nğŸ’¡ Ollama ì„œë²„ ì‹œì‘ ë°©ë²•:")
        print("   í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰: ollama serve")
        return
    
    # 3. ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
    models = get_installed_models()
    
    # 4. ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì„¤ì¹˜ ì œì•ˆ
    if not models:
        print("\nğŸ’¡ ê¶Œì¥ ëª¨ë¸ì„ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        response = input("qwen2.5:3b ëª¨ë¸ì„ ì„¤ì¹˜í•˜ë ¤ë©´ 'y'ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
        if response.lower() in ['y', 'yes', 'ì˜ˆ']:
            if install_recommended_model():
                models = get_installed_models()
    
    # 5. ëª¨ë¸ í…ŒìŠ¤íŠ¸
    if models:
        print(f"\nğŸ§ª ì²« ë²ˆì§¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸: {models[0]}")
        if test_model(models[0]):
            print("\nğŸ‰ Ollama ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("ì´ì œ Excel Agentë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
            print("   uv run streamlit run app.py")
        else:
            print("\nâŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ëª¨ë¸ì„ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("   ollama pull qwen2.5:3b")

if __name__ == "__main__":
    main()