{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama APIë¥¼ ì´ìš©í•œ ë¬¸ì„œ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ doc í´ë”ì˜ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë“¤ì„ ì½ì–´ì„œ Ollama APIë¥¼ í†µí•´ ì§ˆì˜ì‘ë‹µì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import ollama\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¡œë”© í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_markdown_files(doc_folder='doc'):\n",
    "    \"\"\"\n",
    "    doc í´ë”ì˜ ëª¨ë“  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ì½ì–´ì„œ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    documents = {}\n",
    "    doc_path = Path(doc_folder)\n",
    "    \n",
    "    if not doc_path.exists():\n",
    "        print(f\"'{doc_folder}' í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        return documents\n",
    "    \n",
    "    md_files = list(doc_path.glob('*.md'))\n",
    "    \n",
    "    if not md_files:\n",
    "        print(f\"'{doc_folder}' í´ë”ì— ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return documents\n",
    "    \n",
    "    for md_file in md_files:\n",
    "        try:\n",
    "            with open(md_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                documents[md_file.name] = {\n",
    "                    'path': str(md_file),\n",
    "                    'content': content,\n",
    "                    'size': len(content)\n",
    "                }\n",
    "                print(f\"âœ… {md_file.name} ë¡œë”© ì™„ë£Œ ({len(content):,} ë¬¸ì)\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ {md_file.name} ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# ë¬¸ì„œ ë¡œë”©\n",
    "documents = load_markdown_files()\n",
    "print(f\"\\nì´ {len(documents)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë”©ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë¡œë”©ëœ ë¬¸ì„œ ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if documents:\n",
    "    doc_info = []\n",
    "    for filename, doc_data in documents.items():\n",
    "        doc_info.append({\n",
    "            'íŒŒì¼ëª…': filename,\n",
    "            'ê²½ë¡œ': doc_data['path'],\n",
    "            'í¬ê¸°(ë¬¸ì)': f\"{doc_data['size']:,}\",\n",
    "            'ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°': doc_data['content'][:100] + '...' if len(doc_data['content']) > 100 else doc_data['content']\n",
    "        })\n",
    "    \n",
    "    df_docs = pd.DataFrame(doc_info)\n",
    "    display(df_docs)\nelse:\n    print(\"ë¡œë”©ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ollama API ì—°ê²° ë° ëª¨ë¸ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ollama_connection():\n",
    "    \"\"\"\n",
    "    Ollama ì„œë¹„ìŠ¤ ì—°ê²° ë° ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
    "        models = ollama.list()\n",
    "        print(\"ğŸ”— Ollama ì—°ê²° ì„±ê³µ!\")\n",
    "        print(f\"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìˆ˜: {len(models['models'])}\")\n",
    "        \n",
    "        model_list = []\n",
    "        for model in models['models']:\n",
    "            model_list.append({\n",
    "                'ëª¨ë¸ëª…': model['name'],\n",
    "                'í¬ê¸°': f\"{model.get('size', 0) / (1024**3):.1f}GB\" if 'size' in model else 'N/A',\n",
    "                'ìˆ˜ì •ì¼': model.get('modified_at', 'N/A')[:10] if 'modified_at' in model else 'N/A'\n",
    "            })\n",
    "        \n",
    "        if model_list:\n",
    "            df_models = pd.DataFrame(model_list)\n",
    "            display(df_models)\n",
    "            return models['models'][0]['name']  # ì²« ë²ˆì§¸ ëª¨ë¸ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©\n",
    "        else:\n",
    "            print(\"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
    "            print(\"ì˜ˆ: ollama pull llama2\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Ollama ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "        print(\"Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”: ollama serve\")\n",
    "        return None\n",
    "\n",
    "# Ollama ì—°ê²° í™•ì¸\n",
    "default_model = check_ollama_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_documents(question, model_name=None, include_context=True):\n",
    "    \"\"\"\n",
    "    ë¡œë”©ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        return \"ë¡œë”©ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë”©í•´ì£¼ì„¸ìš”.\"\n",
    "    \n",
    "    if not model_name:\n",
    "        model_name = default_model\n",
    "        \n",
    "    if not model_name:\n",
    "        return \"ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    # ëª¨ë“  ë¬¸ì„œ ë‚´ìš©ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©\n",
    "    context = \"\"\n",
    "    for filename, doc_data in documents.items():\n",
    "        context += f\"\\n\\n=== {filename} ===\\n{doc_data['content']}\"\n",
    "    \n",
    "    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    if include_context:\n",
    "        prompt = f\"\"\"ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ë¬¸ì„œ ë‚´ìš©:\n{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€ì€ ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ í•´ì£¼ì„¸ìš”. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.\"\"\"\n",
    "    else:\n",
    "        prompt = question\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ¤– {model_name} ëª¨ë¸ë¡œ ì§ˆì˜ ì¤‘...\")\n",
    "        \n",
    "        # Ollama API í˜¸ì¶œ\n",
    "        response = ollama.chat(model=model_name, messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt\n",
    "            }\n",
    "        ])\n",
    "        \n",
    "        return response['message']['content']\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ ì§ˆì˜ ì‹¤íŒ¨: {e}\"\n",
    "\n",
    "print(\"ì§ˆì˜ì‘ë‹µ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ëŒ€í™”í˜• ì§ˆì˜ì‘ë‹µ ì¸í„°í˜ì´ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_qa():\n",
    "    \"\"\"\n",
    "    ëŒ€í™”í˜• ì§ˆì˜ì‘ë‹µ ì¸í„°í˜ì´ìŠ¤\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ“š ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ì‚¬ìš©ë²•:\")\n",
    "    print(\"- ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ë¡œë”©ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤\")\n",
    "    print(\"- 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤\")\n",
    "    print(\"- '!docs'ë¥¼ ì…ë ¥í•˜ë©´ ë¡œë”©ëœ ë¬¸ì„œ ëª©ë¡ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\nâ“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: \").strip()\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:\n",
    "            print(\"ğŸ‘‹ ì§ˆì˜ì‘ë‹µì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "        \n",
    "        if question == '!docs':\n",
    "            print(\"\\nğŸ“ ë¡œë”©ëœ ë¬¸ì„œ ëª©ë¡:\")\n",
    "            for i, (filename, doc_data) in enumerate(documents.items(), 1):\n",
    "                print(f\"{i}. {filename} ({doc_data['size']:,} ë¬¸ì)\")\n",
    "            continue\n",
    "        \n",
    "        if not question:\n",
    "            print(\"ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        answer = query_documents(question)\n",
    "        print(\"\\nğŸ’¬ ë‹µë³€:\")\n",
    "        print(answer)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "# ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ì‹œì‘ (í•„ìš”ì‹œ ì‹¤í–‰)\n",
    "# interactive_qa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì˜ˆì‹œ ì§ˆì˜ì‘ë‹µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì‹œ ì§ˆë¬¸ë“¤\n",
    "sample_questions = [\n",
    "    \"ë¬¸ì„œì— ì–´ë–¤ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆë‚˜ìš”?\",\n",
    "    \"ì£¼ìš” í‚¤ì›Œë“œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”\",\n",
    "    \"ë¬¸ì„œì˜ êµ¬ì¡°ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“ ì˜ˆì‹œ ì§ˆì˜ì‘ë‹µ:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(sample_questions, 1):\n",
    "    print(f\"\\n{i}. ì§ˆë¬¸: {question}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    answer = query_documents(question)\n",
    "    print(f\"ë‹µë³€: {answer}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì»¤ìŠ¤í…€ ì§ˆì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "custom_question = \"ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”\"\n",
    "\n",
    "if custom_question.strip():\n",
    "    print(f\"â“ ì§ˆë¬¸: {custom_question}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    answer = query_documents(custom_question)\n",
    "    print(f\"\\nğŸ’¬ ë‹µë³€:\")\n",
    "    display(Markdown(answer))\nelse:\n    print(\"ìœ„ì˜ custom_question ë³€ìˆ˜ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ê³ ê¸‰ ê¸°ëŠ¥ - ë¬¸ì„œë³„ ê°œë³„ ì§ˆì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_specific_document(filename, question, model_name=None):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ë¬¸ì„œì— ëŒ€í•´ì„œë§Œ ì§ˆì˜\n",
    "    \"\"\"\n",
    "    if filename not in documents:\n",
    "        return f\"'{filename}' ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    if not model_name:\n",
    "        model_name = default_model\n",
    "    \n",
    "    if not model_name:\n",
    "        return \"ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "    context = documents[filename]['content']\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¤ìŒ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ë¬¸ì„œ: {filename}\n",
    "ë‚´ìš©:\n{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€ì€ ì´ ë¬¸ì„œì˜ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ¤– {model_name} ëª¨ë¸ë¡œ '{filename}' ë¬¸ì„œ ì§ˆì˜ ì¤‘...\")\n",
    "        \n",
    "        response = ollama.chat(model=model_name, messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt\n",
    "            }\n",
    "        ])\n",
    "        \n",
    "        return response['message']['content']\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ ì§ˆì˜ ì‹¤íŒ¨: {e}\"\n",
    "\n",
    "# íŠ¹ì • ë¬¸ì„œ ì§ˆì˜ ì˜ˆì‹œ\n",
    "if documents:\n",
    "    first_doc = list(documents.keys())[0]\n",
    "    print(f\"ğŸ“„ '{first_doc}' ë¬¸ì„œì— ëŒ€í•œ ì§ˆì˜ ì˜ˆì‹œ:\")\n",
    "    \n",
    "    specific_answer = query_specific_document(first_doc, \"ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì´ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "    print(f\"\\në‹µë³€: {specific_answer}\")\nelse:\n    print(\"ì§ˆì˜í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_documents():\n",
    "    \"\"\"\n",
    "    ë¬¸ì„œ ë‹¤ì‹œ ë¡œë”©\n",
    "    \"\"\"\n",
    "    global documents\n",
    "    documents = load_markdown_files()\n",
    "    print(f\"ë¬¸ì„œ ë‹¤ì‹œ ë¡œë”© ì™„ë£Œ: {len(documents)}ê°œ\")\n",
    "\n",
    "def show_document_stats():\n",
    "    \"\"\"\n",
    "    ë¬¸ì„œ í†µê³„ í‘œì‹œ\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        print(\"ë¡œë”©ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    total_chars = sum(doc_data['size'] for doc_data in documents.values())\n",
    "    \n",
    "    print(\"ğŸ“Š ë¬¸ì„œ í†µê³„:\")\n",
    "    print(f\"- ì´ ë¬¸ì„œ ìˆ˜: {len(documents)}ê°œ\")\n",
    "    print(f\"- ì´ ë¬¸ì ìˆ˜: {total_chars:,}ê°œ\")\n",
    "    print(f\"- í‰ê·  ë¬¸ì„œ í¬ê¸°: {total_chars//len(documents):,}ë¬¸ì\")\n",
    "    \n",
    "    print(\"\\nğŸ“ ê°œë³„ ë¬¸ì„œ í¬ê¸°:\")\n",
    "    for filename, doc_data in sorted(documents.items(), key=lambda x: x[1]['size'], reverse=True):\n",
    "        print(f\"  {filename}: {doc_data['size']:,}ë¬¸ì\")\n",
    "\n",
    "def export_qa_session(questions_answers, filename=\"qa_session.json\"):\n",
    "    \"\"\"\n",
    "    ì§ˆì˜ì‘ë‹µ ì„¸ì…˜ì„ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(questions_answers, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"âœ… ì§ˆì˜ì‘ë‹µ ì„¸ì…˜ì´ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# í†µê³„ í‘œì‹œ\n",
    "show_document_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ì‚¬ìš© ê°€ì´ë“œ\n",
    "\n",
    "### ê¸°ë³¸ ì‚¬ìš©ë²•:\n",
    "1. **ë¬¸ì„œ ë¡œë”©**: `documents = load_markdown_files()` - doc í´ë”ì˜ ëª¨ë“  .md íŒŒì¼ì„ ë¡œë”©\n",
    "2. **ì§ˆì˜**: `answer = query_documents(\"ì§ˆë¬¸\")` - ë¡œë”©ëœ ëª¨ë“  ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€\n",
    "3. **íŠ¹ì • ë¬¸ì„œ ì§ˆì˜**: `answer = query_specific_document(\"íŒŒì¼ëª….md\", \"ì§ˆë¬¸\")` - íŠ¹ì • ë¬¸ì„œë§Œ ì‚¬ìš©\n",
    "\n",
    "### ê³ ê¸‰ ê¸°ëŠ¥:\n",
    "- **ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤**: `interactive_qa()` ì‹¤í–‰\n",
    "- **ë¬¸ì„œ í†µê³„**: `show_document_stats()` ì‹¤í–‰\n",
    "- **ë¬¸ì„œ ì¬ë¡œë”©**: `reload_documents()` ì‹¤í–‰\n",
    "\n",
    "### ì£¼ì˜ì‚¬í•­:\n",
    "- Ollamaê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (`ollama serve`)\n",
    "- ìµœì†Œ í•˜ë‚˜ì˜ ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤ (`ollama pull llama2`)\n",
    "- í° ë¬¸ì„œì˜ ê²½ìš° ì‘ë‹µ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}