{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama API를 이용한 문서 질의응답 시스템\n",
    "\n",
    "이 노트북은 doc 폴더의 마크다운 파일들을 읽어서 Ollama API를 통해 질의응답을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import ollama\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "print(\"라이브러리 로딩 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 마크다운 파일 로딩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_markdown_files(doc_folder='doc'):\n",
    "    \"\"\"\n",
    "    doc 폴더의 모든 마크다운 파일을 읽어서 딕셔너리로 반환\n",
    "    \"\"\"\n",
    "    documents = {}\n",
    "    doc_path = Path(doc_folder)\n",
    "    \n",
    "    if not doc_path.exists():\n",
    "        print(f\"'{doc_folder}' 폴더가 존재하지 않습니다.\")\n",
    "        return documents\n",
    "    \n",
    "    md_files = list(doc_path.glob('*.md'))\n",
    "    \n",
    "    if not md_files:\n",
    "        print(f\"'{doc_folder}' 폴더에 마크다운 파일이 없습니다.\")\n",
    "        return documents\n",
    "    \n",
    "    for md_file in md_files:\n",
    "        try:\n",
    "            with open(md_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                documents[md_file.name] = {\n",
    "                    'path': str(md_file),\n",
    "                    'content': content,\n",
    "                    'size': len(content)\n",
    "                }\n",
    "                print(f\"✅ {md_file.name} 로딩 완료 ({len(content):,} 문자)\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {md_file.name} 로딩 실패: {e}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# 문서 로딩\n",
    "documents = load_markdown_files()\n",
    "print(f\"\\n총 {len(documents)}개의 문서가 로딩되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 로딩된 문서 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if documents:\n",
    "    doc_info = []\n",
    "    for filename, doc_data in documents.items():\n",
    "        doc_info.append({\n",
    "            '파일명': filename,\n",
    "            '경로': doc_data['path'],\n",
    "            '크기(문자)': f\"{doc_data['size']:,}\",\n",
    "            '내용 미리보기': doc_data['content'][:100] + '...' if len(doc_data['content']) > 100 else doc_data['content']\n",
    "        })\n",
    "    \n",
    "    df_docs = pd.DataFrame(doc_info)\n",
    "    display(df_docs)\nelse:\n    print(\"로딩된 문서가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ollama API 연결 및 모델 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ollama_connection():\n",
    "    \"\"\"\n",
    "    Ollama 서비스 연결 및 사용 가능한 모델 확인\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 사용 가능한 모델 목록 가져오기\n",
    "        models = ollama.list()\n",
    "        print(\"🔗 Ollama 연결 성공!\")\n",
    "        print(f\"사용 가능한 모델 수: {len(models['models'])}\")\n",
    "        \n",
    "        model_list = []\n",
    "        for model in models['models']:\n",
    "            model_list.append({\n",
    "                '모델명': model['name'],\n",
    "                '크기': f\"{model.get('size', 0) / (1024**3):.1f}GB\" if 'size' in model else 'N/A',\n",
    "                '수정일': model.get('modified_at', 'N/A')[:10] if 'modified_at' in model else 'N/A'\n",
    "            })\n",
    "        \n",
    "        if model_list:\n",
    "            df_models = pd.DataFrame(model_list)\n",
    "            display(df_models)\n",
    "            return models['models'][0]['name']  # 첫 번째 모델을 기본으로 사용\n",
    "        else:\n",
    "            print(\"사용 가능한 모델이 없습니다. 먼저 모델을 다운로드해주세요.\")\n",
    "            print(\"예: ollama pull llama2\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ollama 연결 실패: {e}\")\n",
    "        print(\"Ollama가 실행 중인지 확인해주세요: ollama serve\")\n",
    "        return None\n",
    "\n",
    "# Ollama 연결 확인\n",
    "default_model = check_ollama_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 문서 기반 질의응답 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_documents(question, model_name=None, include_context=True):\n",
    "    \"\"\"\n",
    "    로딩된 문서를 컨텍스트로 사용하여 질문에 답변\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        return \"로딩된 문서가 없습니다. 먼저 문서를 로딩해주세요.\"\n",
    "    \n",
    "    if not model_name:\n",
    "        model_name = default_model\n",
    "        \n",
    "    if not model_name:\n",
    "        return \"사용 가능한 Ollama 모델이 없습니다.\"\n",
    "    \n",
    "    # 모든 문서 내용을 컨텍스트로 결합\n",
    "    context = \"\"\n",
    "    for filename, doc_data in documents.items():\n",
    "        context += f\"\\n\\n=== {filename} ===\\n{doc_data['content']}\"\n",
    "    \n",
    "    # 프롬프트 구성\n",
    "    if include_context:\n",
    "        prompt = f\"\"\"다음 문서들을 기반으로 질문에 답변해주세요:\n",
    "\n",
    "문서 내용:\n{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변은 문서의 내용을 기반으로 정확하고 자세하게 해주세요. 문서에 없는 내용은 추측하지 마세요.\"\"\"\n",
    "    else:\n",
    "        prompt = question\n",
    "    \n",
    "    try:\n",
    "        print(f\"🤖 {model_name} 모델로 질의 중...\")\n",
    "        \n",
    "        # Ollama API 호출\n",
    "        response = ollama.chat(model=model_name, messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt\n",
    "            }\n",
    "        ])\n",
    "        \n",
    "        return response['message']['content']\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"❌ 질의 실패: {e}\"\n",
    "\n",
    "print(\"질의응답 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 대화형 질의응답 인터페이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_qa():\n",
    "    \"\"\"\n",
    "    대화형 질의응답 인터페이스\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"📚 문서 기반 질의응답 시스템\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"사용법:\")\n",
    "    print(\"- 질문을 입력하면 로딩된 문서를 기반으로 답변합니다\")\n",
    "    print(\"- 'quit' 또는 'exit'를 입력하면 종료됩니다\")\n",
    "    print(\"- '!docs'를 입력하면 로딩된 문서 목록을 확인할 수 있습니다\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\n❓ 질문을 입력하세요: \").strip()\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', '종료']:\n",
    "            print(\"👋 질의응답을 종료합니다.\")\n",
    "            break\n",
    "        \n",
    "        if question == '!docs':\n",
    "            print(\"\\n📁 로딩된 문서 목록:\")\n",
    "            for i, (filename, doc_data) in enumerate(documents.items(), 1):\n",
    "                print(f\"{i}. {filename} ({doc_data['size']:,} 문자)\")\n",
    "            continue\n",
    "        \n",
    "        if not question:\n",
    "            print(\"질문을 입력해주세요.\")\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        answer = query_documents(question)\n",
    "        print(\"\\n💬 답변:\")\n",
    "        print(answer)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "# 대화형 인터페이스 시작 (필요시 실행)\n",
    "# interactive_qa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 예시 질의응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 질문들\n",
    "sample_questions = [\n",
    "    \"문서에 어떤 내용이 포함되어 있나요?\",\n",
    "    \"주요 키워드를 요약해주세요\",\n",
    "    \"문서의 구조를 설명해주세요\"\n",
    "]\n",
    "\n",
    "print(\"📝 예시 질의응답:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(sample_questions, 1):\n",
    "    print(f\"\\n{i}. 질문: {question}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    answer = query_documents(question)\n",
    "    print(f\"답변: {answer}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 커스텀 질의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 직접 질문을 입력하여 테스트할 수 있습니다\n",
    "custom_question = \"문서의 주요 내용을 3줄로 요약해주세요\"\n",
    "\n",
    "if custom_question.strip():\n",
    "    print(f\"❓ 질문: {custom_question}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    answer = query_documents(custom_question)\n",
    "    print(f\"\\n💬 답변:\")\n",
    "    display(Markdown(answer))\nelse:\n    print(\"위의 custom_question 변수에 질문을 입력하고 셀을 실행하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 고급 기능 - 문서별 개별 질의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_specific_document(filename, question, model_name=None):\n",
    "    \"\"\"\n",
    "    특정 문서에 대해서만 질의\n",
    "    \"\"\"\n",
    "    if filename not in documents:\n",
    "        return f\"'{filename}' 문서를 찾을 수 없습니다.\"\n",
    "    \n",
    "    if not model_name:\n",
    "        model_name = default_model\n",
    "    \n",
    "    if not model_name:\n",
    "        return \"사용 가능한 Ollama 모델이 없습니다.\"\n",
    "    \n",
    "    context = documents[filename]['content']\n",
    "    \n",
    "    prompt = f\"\"\"다음 문서를 기반으로 질문에 답변해주세요:\n",
    "\n",
    "문서: {filename}\n",
    "내용:\n{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변은 이 문서의 내용만을 기반으로 해주세요.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"🤖 {model_name} 모델로 '{filename}' 문서 질의 중...\")\n",
    "        \n",
    "        response = ollama.chat(model=model_name, messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt\n",
    "            }\n",
    "        ])\n",
    "        \n",
    "        return response['message']['content']\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"❌ 질의 실패: {e}\"\n",
    "\n",
    "# 특정 문서 질의 예시\n",
    "if documents:\n",
    "    first_doc = list(documents.keys())[0]\n",
    "    print(f\"📄 '{first_doc}' 문서에 대한 질의 예시:\")\n",
    "    \n",
    "    specific_answer = query_specific_document(first_doc, \"이 문서의 핵심 내용이 무엇인가요?\")\n",
    "    print(f\"\\n답변: {specific_answer}\")\nelse:\n    print(\"질의할 문서가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 유틸리티 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_documents():\n",
    "    \"\"\"\n",
    "    문서 다시 로딩\n",
    "    \"\"\"\n",
    "    global documents\n",
    "    documents = load_markdown_files()\n",
    "    print(f\"문서 다시 로딩 완료: {len(documents)}개\")\n",
    "\n",
    "def show_document_stats():\n",
    "    \"\"\"\n",
    "    문서 통계 표시\n",
    "    \"\"\"\n",
    "    if not documents:\n",
    "        print(\"로딩된 문서가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    total_chars = sum(doc_data['size'] for doc_data in documents.values())\n",
    "    \n",
    "    print(\"📊 문서 통계:\")\n",
    "    print(f\"- 총 문서 수: {len(documents)}개\")\n",
    "    print(f\"- 총 문자 수: {total_chars:,}개\")\n",
    "    print(f\"- 평균 문서 크기: {total_chars//len(documents):,}문자\")\n",
    "    \n",
    "    print(\"\\n📁 개별 문서 크기:\")\n",
    "    for filename, doc_data in sorted(documents.items(), key=lambda x: x[1]['size'], reverse=True):\n",
    "        print(f\"  {filename}: {doc_data['size']:,}문자\")\n",
    "\n",
    "def export_qa_session(questions_answers, filename=\"qa_session.json\"):\n",
    "    \"\"\"\n",
    "    질의응답 세션을 JSON 파일로 저장\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(questions_answers, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"✅ 질의응답 세션이 '{filename}'에 저장되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 저장 실패: {e}\")\n",
    "\n",
    "# 통계 표시\n",
    "show_document_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 사용 가이드\n",
    "\n",
    "### 기본 사용법:\n",
    "1. **문서 로딩**: `documents = load_markdown_files()` - doc 폴더의 모든 .md 파일을 로딩\n",
    "2. **질의**: `answer = query_documents(\"질문\")` - 로딩된 모든 문서를 기반으로 답변\n",
    "3. **특정 문서 질의**: `answer = query_specific_document(\"파일명.md\", \"질문\")` - 특정 문서만 사용\n",
    "\n",
    "### 고급 기능:\n",
    "- **대화형 인터페이스**: `interactive_qa()` 실행\n",
    "- **문서 통계**: `show_document_stats()` 실행\n",
    "- **문서 재로딩**: `reload_documents()` 실행\n",
    "\n",
    "### 주의사항:\n",
    "- Ollama가 실행 중이어야 합니다 (`ollama serve`)\n",
    "- 최소 하나의 모델이 설치되어 있어야 합니다 (`ollama pull llama2`)\n",
    "- 큰 문서의 경우 응답 시간이 오래 걸릴 수 있습니다\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}