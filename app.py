from openai import OpenAI
import streamlit as st
import pandas as pd
import json
import re
from dotenv import load_dotenv
import os
import requests
import re
import logging
import traceback
load_dotenv()

# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì • í•¨ìˆ˜"""
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    current_dir = os.path.dirname(os.path.abspath(__file__))
    log_file_path = os.path.join(current_dir, 'app.log')
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file_path, encoding='utf-8'),
            logging.StreamHandler()
        ],
        force=True  # ê¸°ì¡´ ì„¤ì • ê°•ì œ ë®ì–´ì“°ê¸°
    )
    
    # ë¡œê·¸ íŒŒì¼ ìƒì„± í™•ì¸
    try:
        logging.info("ğŸš€ ë¡œê¹… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        logging.info(f"ğŸ“ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {log_file_path}")
        print(f"ğŸ“ ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜: {log_file_path}")
        return log_file_path
    except Exception as e:
        print(f"âŒ ë¡œê·¸ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        # íŒŒì¼ ë¡œê¹… ì‹¤íŒ¨ ì‹œ ì½˜ì†”ë§Œ ì‚¬ìš©
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[logging.StreamHandler()],
            force=True
        )
        return None

# ë¡œê¹… ì´ˆê¸°í™”
log_file_path = setup_logging()


#######################  llm í˜¸ì¶œ í•¨ìˆ˜ ########################

def llm_call_openai(prompt: str, model: str = "gpt-4o-mini") -> str:
    """
    ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¡œ OpenAI LLMì„ ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    openai_api_key = os.getenv("OPENAI_API_KEY")
    
    # API í‚¤ ì •ë¦¬ (ê³µë°±, ì¤„ë°”ê¿ˆ ì œê±°)
    if openai_api_key:
        openai_api_key = openai_api_key.strip()
    
    logging.info(f"ğŸ”‘ API í‚¤ í™•ì¸: {'ì„¤ì •ë¨' if openai_api_key else 'ì—†ìŒ'}")
    if openai_api_key:
        logging.info(f"ğŸ”‘ API í‚¤ ê¸¸ì´: {len(openai_api_key)} ë¬¸ì")
        logging.info(f"ğŸ”‘ API í‚¤ ì‹œì‘: {openai_api_key[:10]}...")
    
    logging.info(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {model}")
    logging.info(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
    
    if not openai_api_key:
        raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    try:
        client = OpenAI(api_key=openai_api_key)
        messages = [{"role": "user", "content": prompt}]
        
        logging.info("ğŸ“¡ OpenAI API í˜¸ì¶œ ì‹œì‘...")
        chat_completion = client.chat.completions.create(
            model=model,
            messages=messages,
        )
        
        response_content = chat_completion.choices[0].message.content
        logging.info(f"âœ… OpenAI API í˜¸ì¶œ ì„±ê³µ - ì‘ë‹µ ê¸¸ì´: {len(response_content)} ë¬¸ì")
        print(model, "ì™„ë£Œ")
        return response_content
        
    except Exception as e:
        logging.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        logging.error(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        
        # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ í•´ì„
        error_str = str(e)
        if "401" in error_str or "Unauthorized" in error_str:
            logging.error("ğŸš¨ ì¸ì¦ ì˜¤ë¥˜: API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        elif "400" in error_str or "Bad Request" in error_str:
            logging.error("ğŸš¨ ì˜ëª»ëœ ìš”ì²­: ëª¨ë¸ëª…ì´ë‚˜ ìš”ì²­ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        elif "429" in error_str:
            logging.error("ğŸš¨ ìš”ì²­ í•œë„ ì´ˆê³¼: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        elif "500" in error_str:
            logging.error("ğŸš¨ ì„œë²„ ì˜¤ë¥˜: OpenAI ì„œë²„ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            
        raise e



# ë§Œì•½ ollamaë¥¼ ì´ìš©í•  ê²½ìš° í™œìš©


def llm_call(prompt: str) -> str:
    """
    ì‚¬ìš©ìê°€ ì„ íƒí•œ LLM ì„œë¹„ìŠ¤ì™€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í˜¸ì¶œ
    """
    
    # ì„¸ì…˜ ìƒíƒœì—ì„œ ì„ íƒëœ ì„œë¹„ìŠ¤ì™€ ëª¨ë¸ í™•ì¸
    if not hasattr(st.session_state, 'llm_service') or not hasattr(st.session_state, 'selected_model'):
        # ê¸°ë³¸ê°’ ì„¤ì • (Ollama ìš°ì„ )
        if check_ollama_connection():
            st.session_state.llm_service = "ollama"
            models = get_available_ollama_models()
            st.session_state.selected_model = models[0] if models else "qwen3:latest"
        elif os.getenv("OPENAI_API_KEY"):
            st.session_state.llm_service = "openai"
            st.session_state.selected_model = "gpt-4o-mini"
        else:
            raise Exception("ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì„œë¹„ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. Ollamaë¥¼ ì„¤ì¹˜í•˜ê±°ë‚˜ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    service = st.session_state.llm_service
    model = st.session_state.selected_model
    
    logging.info(f"ğŸ¯ ì„ íƒëœ ì„œë¹„ìŠ¤: {service}, ëª¨ë¸: {model}")
    
    try:
        if service == "ollama":
            logging.info(f"ğŸ¦™ Ollama ëª¨ë¸ í˜¸ì¶œ: {model}")
            return llm_call_ollama(prompt, model)
        elif service == "openai":
            logging.info(f"ğŸ¤– OpenAI ëª¨ë¸ í˜¸ì¶œ: {model}")
            return llm_call_openai(prompt, model)
        else:
            raise Exception(f"ì•Œ ìˆ˜ ì—†ëŠ” ì„œë¹„ìŠ¤: {service}")
            
    except Exception as e:
        logging.error(f"âŒ {service} í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        
        # ì‚¬ìš©ìì—ê²Œ ì˜¤ë¥˜ í‘œì‹œ
        if service == "ollama":
            st.error(f"âŒ Ollama ëª¨ë¸ '{model}' í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            st.info("ğŸ’¡ í•´ê²° ë°©ë²•: 'ollama serve' ëª…ë ¹ìœ¼ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        elif service == "openai":
            st.error(f"âŒ OpenAI ëª¨ë¸ '{model}' í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            if "insufficient_quota" in str(e) or "429" in str(e):
                st.info("ğŸ’¡ í•´ê²° ë°©ë²•: OpenAI ê³„ì •ì— í¬ë ˆë”§ì„ ì¶”ê°€í•˜ê±°ë‚˜ Ollamaë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.")
        
        raise e

def check_ollama_connection() -> bool:
    """Ollama ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False

def get_available_ollama_models() -> list:
    """ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            return [model["name"] for model in models]
        return []
    except:
        return []

def llm_call_ollama(prompt: str, model: str = None) -> str:
    """
    Ollamaì˜ REST APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ ëª¨ë¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """

    def remove_think_tags(text: str) -> str:
        """
        Removes all content enclosed in <think>...</think> tags from the input text.
        """
        # ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ <think> íƒœê·¸ ì œê±°
        patterns = [
            r"<think>.*?</think>",  # ê¸°ë³¸ íŒ¨í„´
            r"<think>[\s\S]*?</think>",  # ì¤„ë°”ê¿ˆ í¬í•¨
            r"<think>.*",  # ë‹«ëŠ” íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°
        ]
        
        cleaned_text = text
        for pattern in patterns:
            cleaned_text = re.sub(pattern, "", cleaned_text, flags=re.DOTALL | re.IGNORECASE)
        
        # ì¶”ê°€ ì •ë¦¬: ì—°ì†ëœ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì •ë¦¬
        cleaned_text = re.sub(r'\n\s*\n', '\n', cleaned_text)  # ì—°ì†ëœ ë¹ˆ ì¤„ ì œê±°
        cleaned_text = re.sub(r'^\s+', '', cleaned_text, flags=re.MULTILINE)  # ì¤„ ì‹œì‘ ê³µë°± ì œê±°
        
        return cleaned_text.strip()

    # 1. ì„œë²„ ì—°ê²° í™•ì¸
    if not check_ollama_connection():
        raise Exception("Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'ollama serve' ëª…ë ¹ìœ¼ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.")
    
    # 2. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
    available_models = get_available_ollama_models()
    logging.info(f"ğŸ¦™ ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸: {available_models}")
    
    if not available_models:
        raise Exception("ì„¤ì¹˜ëœ Ollama ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ollama pull qwen2.5:3b' ëª…ë ¹ìœ¼ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
    
    # 3. ëª¨ë¸ ì„ íƒ
    if model and model in available_models:
        selected_model = model
        logging.info(f"ğŸ¯ ì‚¬ìš©ì ì§€ì • ëª¨ë¸ ì‚¬ìš©: {selected_model}")
    else:
        # ì§€ì •ëœ ëª¨ë¸ì´ ì—†ê±°ë‚˜ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì„ íƒ
        preferred_models = ["qwen2.5:3b", "qwen2.5:7b", "qwen2.5:1.5b", "qwen3:latest", "llama3.2:3b", "llama3.1:latest", "llama3.1:8b"]
        selected_model = None
        
        for preferred_model in preferred_models:
            if preferred_model in available_models:
                selected_model = preferred_model
                break
        
        if not selected_model:
            # ìš°ì„ ìˆœìœ„ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì‚¬ìš©
            selected_model = available_models[0]
        
        logging.info(f"ğŸ¦™ ìë™ ì„ íƒëœ Ollama ëª¨ë¸: {selected_model}")
    
    # 4. API í˜¸ì¶œ
    url = "http://localhost:11434/api/generate"
    headers = {"Content-Type": "application/json"}
    payload = {
        "model": selected_model,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.7,
            "top_p": 0.9,
            "num_predict": 2048
        }
    }
    
    try:
        logging.info(f"ğŸ¦™ Ollama API í˜¸ì¶œ ì‹œì‘...")
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=120)
        
        if response.status_code != 200:
            error_detail = response.text if response.text else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
            raise Exception(f"Ollama API í˜¸ì¶œ ì‹¤íŒ¨ (HTTP {response.status_code}): {error_detail}")

        result = response.json()
        
        if "response" not in result:
            raise Exception(f"Ollama ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {result}")
        
        response_text = result["response"]
        logging.info(f"âœ… Ollama í˜¸ì¶œ ì„±ê³µ - ì‘ë‹µ ê¸¸ì´: {len(response_text)} ë¬¸ì")
        print(f"{selected_model} ì™„ë£Œ")
        
        # <think> íƒœê·¸ ì œê±°
        cleaned_response = remove_think_tags(response_text)
        logging.info(f"ğŸ§¹ <think> íƒœê·¸ ì œê±° í›„ ê¸¸ì´: {len(cleaned_response)} ë¬¸ì")
        
        return cleaned_response
        
    except requests.exceptions.Timeout:
        raise Exception("Ollama ì‘ë‹µ ì‹œê°„ ì´ˆê³¼. ëª¨ë¸ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ì„œë²„ê°€ ê³¼ë¶€í•˜ ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    except requests.exceptions.ConnectionError:
        raise Exception("Ollama ì„œë²„ ì—°ê²° ëŠê¹€. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        logging.error(f"âŒ Ollama í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        raise e

#######################  íŒŒì¼ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° ########################

def detect_file_encoding(uploaded_file):
    """ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì¸ì½”ë”©ì„ ê°ì§€í•©ë‹ˆë‹¤"""
    try:
        # chardet ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
        import chardet
        
        # íŒŒì¼ì˜ ì¼ë¶€ë¥¼ ì½ì–´ì„œ ì¸ì½”ë”© ê°ì§€
        uploaded_file.seek(0)
        raw_data = uploaded_file.read(10000)  # ì²˜ìŒ 10KBë§Œ ì½ê¸°
        uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
        
        result = chardet.detect(raw_data)
        detected_encoding = result.get('encoding', 'utf-8')
        confidence = result.get('confidence', 0)
        
        logging.info(f"ğŸ” ê°ì§€ëœ ì¸ì½”ë”©: {detected_encoding} (ì‹ ë¢°ë„: {confidence:.2f})")
        return detected_encoding
        
    except ImportError:
        logging.info("ğŸ“ chardet ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ê¸°ë³¸ ì¸ì½”ë”© ìˆœì„œë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
        return None
    except Exception as e:
        logging.warning(f"âš ï¸ ì¸ì½”ë”© ê°ì§€ ì‹¤íŒ¨: {e}")
        return None

#######################  1ë‹¨ê³„ : code ìƒì„± ########################
def generate_code_prompt(user_query: str, df_preview: dict, df_types: dict) -> str:
    print("ğŸ“Œ df íƒ€ì…ì •ë³´")
    print(json.dumps(df_types, ensure_ascii=False, indent=2))

    # dict â†’ pretty JSON string
    preview_str = json.dumps(df_preview, ensure_ascii=False, indent=2)
    types_str = json.dumps(df_types, ensure_ascii=False, indent=2)
    prompt = f"""
    ë‹¤ìŒì€ pandas DataFrame(df)ì˜ ë¯¸ë¦¬ë³´ê¸°ì…ë‹ˆë‹¤:
    {preview_str}

    ê° ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    {types_str}

    ë‹¤ìŒ ì‚¬ìš©ì ì§ˆì˜ì— ê¸°ë°˜í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” Python ì½”ë“œë¥¼ ìƒì„±í•˜ì„¸ìš”:
    "{user_query}"

    ì½”ë“œëŠ” `df`ê°€ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ê³ , ìµœì¢… ê²°ê³¼ëŠ” ìƒˆë¡œìš´ DataFrame `final_df`ë¡œ ë°˜í™˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

    ë‹¨, ì‚¬ìš©ì ì§ˆì˜ê°€ ë‹¨ì¼ ê°’ì„ ë¬»ëŠ” ì§ˆë¬¸(ì˜ˆ: ìµœëŒ€ê°’, ìµœì†Œê°’, ìƒìœ„ 1ê°œ ë“±)ì´ë¼ í•˜ë”ë¼ë„,
    `final_df`ì—ëŠ” ê´€ë ¨ëœ ì „ì²´ ë§¥ë½ì´ ë‹´ê²¨ì•¼ í•©ë‹ˆë‹¤.
    ì˜ˆë¥¼ ë“¤ì–´, "ê°€ì¥ ì¸µì´ ë†’ì€ í–‰ì •êµ¬ëŠ”?"ì´ë¼ëŠ” ì§ˆë¬¸ì´ë¼ë©´,
    í•´ë‹¹ ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ëœ ëª¨ë“  í–‰ì •êµ¬ ì •ë³´ë¥¼ í¬í•¨í•œ DataFrameì„ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

    ì¦‰, ë‹¨ì¼ ê°’ë§Œ ì¶”ì¶œí•˜ì§€ ë§ê³ , ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë¹„êµ/ì •ë ¬/ë¹„ìœ¨ ë“±ì˜ ì¶”ê°€ì ì´ê³  ê´€ë ¨ ìˆëŠ” ì •ë³´ë¥¼ í•¨ê»˜ í¬í•¨í•˜ì„¸ìš”.

    **ì¤‘ìš”í•œ ìš”êµ¬ì‚¬í•­:**
    1. ìƒì„±ëœ ì½”ë“œëŠ” ë°˜ë“œì‹œ <result></result> XML íƒœê·¸ ì•ˆì— ì‘ì„±í•´ì£¼ì„¸ìš”.
    2. importë¬¸ì´ë‚˜ printë¬¸ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    3. ì½”ë“œëŠ” ë°˜ë“œì‹œ `final_df = ...` í˜•íƒœë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤.
    4. <think> íƒœê·¸ë‚˜ ì„¤ëª…ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì½”ë“œë§Œ ì‘ì„±í•˜ì„¸ìš”.

    ## ì‘ë‹µ ì˜ˆì‹œ
    <result>
    sorted_df = df.groupby("í–‰ì •êµ¬")["ì¸µìˆ˜"].max().reset_index()
    sorted_df = sorted_df.sort_values(by="ì¸µìˆ˜", ascending=False)
    final_df = sorted_df
    </result>
    
    ## í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ì½”ë“œë§Œ <result> íƒœê·¸ ì•ˆì— ì‘ì„±í•´ì£¼ì„¸ìš”.
    """
    return prompt

#######################  2ë‹¨ê³„ : code ì¶”ì¶œ ë° ì‹¤í–‰ ########################


def extract_code_from_response(response: str) -> str:
    """
    LLM ì‘ë‹µì—ì„œ Python ì½”ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì—¬ëŸ¬ íŒ¨í„´ì„ ì‹œë„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì½”ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    
    logging.info(f"ğŸ” ì½”ë“œ ì¶”ì¶œ ì‹œì‘ - ì‘ë‹µ ê¸¸ì´: {len(response)} ë¬¸ì")
    
    # 1. <result> íƒœê·¸ ìš°ì„  ì¶”ì¶œ
    result_patterns = [
        r"<result>(.*?)</result>",
        r"<code>(.*?)</code>",
        r"<python>(.*?)</python>"
    ]
    
    for pattern in result_patterns:
        match = re.search(pattern, response, re.DOTALL | re.IGNORECASE)
        if match:
            code_block = match.group(1)
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ëŸ­ í‘œì‹œ ì œê±°
            code_block = re.sub(r"```[a-zA-Z]*\n?", "", code_block)
            code_block = re.sub(r"```\n?", "", code_block)
            code_block = code_block.strip()
            
            if code_block:
                logging.info(f"âœ… {pattern} íƒœê·¸ì—ì„œ ì½”ë“œ ì¶”ì¶œ ì„±ê³µ - ê¸¸ì´: {len(code_block)} ë¬¸ì")
                return code_block

    # 2. ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ëŸ­ì—ì„œ ì¶”ì¶œ
    markdown_patterns = [
        r"```python\n(.*?)```",
        r"```py\n(.*?)```", 
        r"```\n(.*?)```",
        r"```(.*?)```"
    ]
    
    for pattern in markdown_patterns:
        match = re.search(pattern, response, re.DOTALL)
        if match:
            code_block = match.group(1).strip()
            if code_block and any(keyword in code_block.lower() for keyword in ['df', 'final_df', 'pandas', 'groupby']):
                logging.info(f"âœ… ë§ˆí¬ë‹¤ìš´ ë¸”ëŸ­ì—ì„œ ì½”ë“œ ì¶”ì¶œ ì„±ê³µ - ê¸¸ì´: {len(code_block)} ë¬¸ì")
                return code_block

    # 3. ì§ì ‘ Python ì½”ë“œ íŒ¨í„´ ì°¾ê¸°
    # final_dfê°€ í¬í•¨ëœ ë¼ì¸ë“¤ì„ ì°¾ì•„ì„œ ì½”ë“œ ë¸”ëŸ­ ì¶”ì •
    lines = response.split('\n')
    code_lines = []
    in_code_block = False
    
    for line in lines:
        line = line.strip()
        
        # Python ì½”ë“œë¡œ ë³´ì´ëŠ” ë¼ì¸ ê°ì§€
        if any(keyword in line for keyword in ['df[', 'df.', 'final_df', 'pd.', 'groupby', 'value_counts', 'reset_index']):
            in_code_block = True
            code_lines.append(line)
        elif in_code_block and (line.startswith('final_df') or 'final_df' in line):
            code_lines.append(line)
            break  # final_df í• ë‹¹ìœ¼ë¡œ ë
        elif in_code_block and line and not line.startswith('#') and '=' in line:
            code_lines.append(line)
        elif in_code_block and not line:
            continue  # ë¹ˆ ì¤„ì€ ê±´ë„ˆë›°ê¸°
        elif in_code_block:
            break  # ì½”ë“œ ë¸”ëŸ­ ë
    
    if code_lines:
        extracted_code = '\n'.join(code_lines)
        logging.info(f"âœ… ì§ì ‘ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ì½”ë“œ ì¶”ì¶œ ì„±ê³µ - ê¸¸ì´: {len(extracted_code)} ë¬¸ì")
        return extracted_code

    # 4. ë§ˆì§€ë§‰ ì‹œë„: ì „ì²´ ì‘ë‹µì—ì„œ Python ì½”ë“œ ê°™ì€ ë¶€ë¶„ ì°¾ê¸°
    # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: dfë‚˜ pandas ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ” ë¼ì¸ë“¤
    potential_code_lines = []
    for line in response.split('\n'):
        line = line.strip()
        if line and any(keyword in line for keyword in ['df', 'pd.', 'import pandas', 'final_df']):
            potential_code_lines.append(line)
    
    if potential_code_lines:
        fallback_code = '\n'.join(potential_code_lines)
        logging.warning(f"âš ï¸ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì½”ë“œ ì¶”ì¶œ ì‹œë„ - ê¸¸ì´: {len(fallback_code)} ë¬¸ì")
        return fallback_code

    logging.error("âŒ ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨ - ì‘ë‹µì—ì„œ ìœ íš¨í•œ Python ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    return ""

def execute_generated_code(code: str, df: pd.DataFrame, max_retries: int = 3):
    current_code = code
    error_history = []
    
    for attempt in range(max_retries):
        try:
            local_vars = {"df": df, "final_df": None}
            exec(current_code, {}, local_vars)
            return local_vars.get("final_df", None)
        except Exception as e:
            error_message = str(e)
            error_history.append(f"Attempt {attempt + 1} failed: {error_message}")
            
            if attempt < max_retries - 1:  # ë§ˆì§€ë§‰ ì‹œë„ì—ëŠ” ìƒˆë¡œìš´ ì½”ë“œ ìƒì„±í•˜ì§€ ì•ŠìŒ
                # ì½”ë“œ ìˆ˜ì •ì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ìƒì„±
                error_prompt = f"""
                ë‹¤ìŒ ì½”ë“œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:
                {current_code}
                
                ì˜¤ë¥˜ ë©”ì‹œì§€:
                {error_message}
                
                ì´ì „ì— ë°œìƒí•œ ì˜¤ë¥˜ë“¤:
                {chr(10).join(error_history[:-1])}
                
                1. ëª¨ë“  ë°ì´í„° íƒ€ì… ë³€í™˜ ë¬¸ì œ ì²˜ë¦¬
                2. ëˆ„ë½ë˜ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ ì²˜ë¦¬
                3. ì ì ˆí•œ ë°ì´í„° íƒ€ì… ì²˜ë¦¬ ì‚¬ìš©
                4. 'final_df'ë¼ëŠ” ì´ë¦„ì˜ í•„í„°ë§ëœ DataFrame ë˜ëŠ” í”¼ë²— í…Œì´ë¸” ë°˜í™˜
                5. ë™ì¼í•œ ë¬¸ì œê°€ ë°˜ë³µë˜ì§€ ì•Šë„ë¡ ì´ì „ ì˜¤ë¥˜ ê³ ë ¤
                
                ìˆ˜ì •ëœ ì½”ë“œëŠ” <result></result> XML íƒœê·¸ ì•ˆì— ì‘ì„±í•´ì£¼ì„¸ìš”.
                """
                
                # LLMì—ì„œ ìˆ˜ì •ëœ ì½”ë“œ ì¶”ì¶œ
                corrected_response = llm_call(error_prompt)
                corrected_code = extract_code_from_response(corrected_response)
                
                if corrected_code:
                    current_code = corrected_code
                else:
                    return f"ì½”ë“œ ìˆ˜ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ê¸°ë¡: {chr(10).join(error_history)}"
            else:
                return f"ìµœëŒ€ ì‹œë„ íšŸìˆ˜({max_retries})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ê¸°ë¡: {chr(10).join(error_history)}"
    
    return f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {chr(10).join(error_history)}"


#######################  3ë‹¨ê³„ : ë‹µë³€ ìƒì„± ########################


def generate_final_prompt(user_query: str, filtered_df: pd.DataFrame) -> str:
    try:
        filtered_json = json.dumps(json.loads(filtered_df.to_json()), ensure_ascii=False)
    except Exception as e:
        filtered_json = "{}"  # fallback in case of an error
    
    context_json = json.dumps({"query": user_query, "data": filtered_json}, ensure_ascii=False)
    prompt = f"""
    ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ê°€ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤:
    {context_json}
    ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ë‹µë³€ì€ ëª…í™•í•˜ê³  ê°„ê²°í•´ì•¼ í•˜ë©°, ë¶ˆí•„ìš”í•œ í¬ë§·íŒ…ì´ë‚˜ ì¸ì½”ë”© ë¬¸ì œê°€ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
    - ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
    return prompt


def test_logging():
    """ë¡œê¹… í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    try:
        logging.info("ğŸ§ª ë¡œê¹… í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€")
        logging.warning("âš ï¸ ê²½ê³  í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€")
        logging.error("âŒ ì˜¤ë¥˜ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€")
        return True
    except Exception as e:
        print(f"ë¡œê¹… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    st.title("ë‚´ ì—‘ì…€ë°ì´í„°ì™€ ëŒ€í™”í•˜ê¸°")
    
    # í˜ì´ì§€ ë¡œë“œ ì‹œ ë¡œê¹… í…ŒìŠ¤íŠ¸
    if 'logging_tested' not in st.session_state:
        st.session_state.logging_tested = True
        test_logging()
    
    # ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ì„ íƒ ì˜µì…˜ ì¶”ê°€
    with st.sidebar:
        st.header("ğŸ¤– ëª¨ë¸ ì„¤ì •")
        
        # LLM ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
        ollama_available = check_ollama_connection()
        openai_available = bool(os.getenv("OPENAI_API_KEY"))
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ ì˜µì…˜ ìƒì„±
        service_options = []
        if ollama_available:
            service_options.append("ğŸ¦™ Ollama (ë¡œì»¬)")
        if openai_available:
            service_options.append("ğŸ¤– OpenAI (í´ë¼ìš°ë“œ)")
        
        if not service_options:
            st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì„œë¹„ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
            st.info("Ollamaë¥¼ ì„¤ì¹˜í•˜ê±°ë‚˜ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return
        
        # LLM ì„œë¹„ìŠ¤ ì„ íƒ
        selected_service = st.selectbox(
            "LLM ì„œë¹„ìŠ¤ ì„ íƒ:",
            service_options,
            index=0
        )
        
        # ì„ íƒëœ ì„œë¹„ìŠ¤ì— ë”°ë¥¸ ëª¨ë¸ ì˜µì…˜
        if "Ollama" in selected_service and ollama_available:
            available_models = get_available_ollama_models()
            if available_models:
                st.write("**ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸:**")
                selected_model = st.selectbox(
                    "ëª¨ë¸ ì„ íƒ:",
                    available_models,
                    index=0
                )
                
                # ëª¨ë¸ ì •ë³´ í‘œì‹œ
                st.info(f"ì„ íƒëœ ëª¨ë¸: {selected_model}")
                
                # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                st.session_state.llm_service = "ollama"
                st.session_state.selected_model = selected_model
            else:
                st.error("ì„¤ì¹˜ëœ Ollama ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.code("ollama pull qwen2.5:3b")
                
        elif "OpenAI" in selected_service and openai_available:
            openai_models = [
                "gpt-4o-mini",
                "gpt-4o", 
                "gpt-4-turbo",
                "gpt-3.5-turbo"
            ]
            
            selected_model = st.selectbox(
                "OpenAI ëª¨ë¸ ì„ íƒ:",
                openai_models,
                index=0
            )
            
            st.info(f"ì„ íƒëœ ëª¨ë¸: {selected_model}")
            st.warning("âš ï¸ OpenAI ì‚¬ìš© ì‹œ ìš”ê¸ˆì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.llm_service = "openai"
            st.session_state.selected_model = selected_model
        
        # ëª¨ë¸ ìƒíƒœ í‘œì‹œ
        st.write("---")
        st.write("**í˜„ì¬ ì„¤ì •:**")
        if hasattr(st.session_state, 'llm_service'):
            service_name = "Ollama" if st.session_state.llm_service == "ollama" else "OpenAI"
            st.success(f"ì„œë¹„ìŠ¤: {service_name}")
            st.success(f"ëª¨ë¸: {st.session_state.selected_model}")
        
        # ë¡œê·¸ íŒŒì¼ ìƒíƒœ í‘œì‹œ
        st.write("---")
        st.write("**ë¡œê·¸ ìƒíƒœ**")
        if log_file_path and os.path.exists(log_file_path):
            file_size = os.path.getsize(log_file_path)
            st.success(f"ğŸ“ ë¡œê·¸: {file_size} bytes")
            
            # ë¡œê·¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            if st.button("ğŸ“¥ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ"):
                with open(log_file_path, 'r', encoding='utf-8') as f:
                    log_content = f.read()
                st.download_button(
                    label="ğŸ’¾ app.log ë‹¤ìš´ë¡œë“œ",
                    data=log_content,
                    file_name="app.log",
                    mime="text/plain"
                )
        else:
            st.warning("ğŸ“ ë¡œê·¸: íŒŒì¼ ì—†ìŒ")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["xls", "xlsx", "csv"])
    if uploaded_file:
        file_type = uploaded_file.name.split('.')[-1].lower()
        
        if file_type == 'csv':
            # CSV íŒŒì¼ ì¸ì½”ë”© ìë™ ê°ì§€ ë° ì²˜ë¦¬
            try:
                df = pd.read_csv(uploaded_file, encoding='utf-8')
                logging.info("âœ… CSV íŒŒì¼ì„ UTF-8ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            except UnicodeDecodeError:
                try:
                    # í•œêµ­ì–´ CSV íŒŒì¼ì˜ ê²½ìš° EUC-KR ë˜ëŠ” CP949 ì‹œë„
                    uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                    df = pd.read_csv(uploaded_file, encoding='euc-kr')
                    logging.info("âœ… CSV íŒŒì¼ì„ EUC-KRë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                except UnicodeDecodeError:
                    try:
                        uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                        df = pd.read_csv(uploaded_file, encoding='cp949')
                        logging.info("âœ… CSV íŒŒì¼ì„ CP949ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    except UnicodeDecodeError:
                        try:
                            uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                            df = pd.read_csv(uploaded_file, encoding='latin1')
                            logging.info("âœ… CSV íŒŒì¼ì„ Latin1ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                        except Exception as e:
                            st.error(f"âŒ CSV íŒŒì¼ ì¸ì½”ë”©ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                            st.info("ğŸ’¡ í•´ê²° ë°©ë²•: CSV íŒŒì¼ì„ UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì €ì¥í•´ì£¼ì„¸ìš”.")
                            return
        else:
            try:
                df = pd.read_excel(uploaded_file)
                logging.info("âœ… Excel íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ Excel íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                st.info("ğŸ’¡ í•´ê²° ë°©ë²•: íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return

        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ: {uploaded_file.name}")
        st.info(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(df)}í–‰ Ã— {len(df.columns)}ì—´")
        
        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°(ì‚¬ëŒìš©)"):
            st.dataframe(df.head(5))

        df_preview = df.head(5).to_dict(orient="records")
        with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°(LLMìš©)"):
            st.json(df_preview)
        
        df_types = df.dtypes.apply(lambda x: str(x)).to_dict()
        with st.expander("ë°ì´í„°íƒ€ì… ë¯¸ë¦¬ë³´ê¸°(LLMìš©)"):
            st.json(df_types)
        
        questions = [
            "ì„œìš¸ì—ì„œ ì—…ì¢…ë³„(ëŒ€ë¶„ë¥˜)ë¡œ ê°€ì¥ ë§ì€ ìƒì ì´ ìˆëŠ” êµ¬ëŠ” ì–´ë””ì¸ê°€ìš”?",
            "ì„œìš¸ì—ì„œ ì¹´í˜ê°€ ìœ„ì¹˜í•œ í‰ê·  ì¸µìˆ˜ê°€ ê°€ì¥ ë†’ì€ êµ¬ëŠ” ì–´ë””ì¸ê°€ìš”?", 
            "ì„œìš¸ì—ì„œ ë¶€ë™ì‚° ì¤‘ê°œì—…ì´ ì „ì²´ ìƒê°€ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘ì´ ê°€ì¥ ë†’ì€ ì§€ì—­ì€ ì–´ë””ì¸ê°€ìš”?",
            "ì„±ë™êµ¬ì—ì„œ ì—…ì¢…ë³„(ì¤‘ë¶„ë¥˜) ìƒì  ë¹„ì¤‘ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        ]

        if "user_query" not in st.session_state:
            st.session_state["user_query"] = ""

        user_input = st.text_input(
            "ë°ì´í„°ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”:",
            key="input_box"
        )

        if not user_input:
            sample = st.selectbox("ë˜ëŠ” ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", questions, key="sample_box")
            user_query = sample
        else:
            user_query = user_input

        if st.button("ì§ˆë¬¸í•˜ê¸°"):
            st.session_state["user_query"] = user_query
            if user_query:
                try:
                    logging.info(f"ğŸš€ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {user_query}")
                    
                    # 1ë‹¨ê³„: ì½”ë“œ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±
                    logging.info("ğŸ“‹ 1ë‹¨ê³„: ì½”ë“œ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
                    code_prompt = generate_code_prompt(user_query, df_preview, df_types)
                    print("ìƒì„±ëœ ì½”ë“œ í”„ë¡¬í”„íŠ¸")
                    print(code_prompt)
                    
                    # 2ë‹¨ê³„: LLM í˜¸ì¶œë¡œ ì½”ë“œ ìƒì„±
                    logging.info("ğŸ¤– 2ë‹¨ê³„: LLM í˜¸ì¶œë¡œ ì½”ë“œ ìƒì„± ì¤‘...")
                    generated_response = llm_call(code_prompt)
                    print("ìƒì„±ëœ ì½”ë“œ")
                    print(generated_response)   
                    
                    # 3ë‹¨ê³„: ì½”ë“œ ì¶”ì¶œ
                    logging.info("ğŸ” 3ë‹¨ê³„: ìƒì„±ëœ ì‘ë‹µì—ì„œ ì½”ë“œ ì¶”ì¶œ ì¤‘...")
                    generated_code = extract_code_from_response(generated_response)
                    print("ìƒì„±ëœ ì½”ë“œ ì¶”ì¶œ")
                    print(generated_code)
                    
                    # 4ë‹¨ê³„: ì½”ë“œ ì‹¤í–‰
                    logging.info("âš™ï¸ 4ë‹¨ê³„: ìƒì„±ëœ ì½”ë“œ ì‹¤í–‰ ì¤‘...")
                    filtered_df = execute_generated_code(generated_code, df)
                    
                    if isinstance(filtered_df, pd.DataFrame):
                        logging.info("âœ… ì½”ë“œ ì‹¤í–‰ ì„±ê³µ - DataFrame ìƒì„±ë¨")
                        
                        # 5ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìƒì„±
                        logging.info("ğŸ“ 5ë‹¨ê³„: ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘...")
                        final_prompt = generate_final_prompt(user_query, filtered_df)
                        final_response = llm_call(final_prompt)
                        
                        logging.info("ğŸ‰ ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ!")
                        
                        st.write("### ë‹µë³€")
                        st.write(final_response)
                        
                        with st.expander("ë‹µë³€ ê·¼ê±°"):
                            st.write("### ìƒì„±ëœ ì½”ë“œ")
                            st.code(generated_code, language="python")

                            st.write("### í•„í„°ë§ëœ ë°ì´í„°") 
                            st.dataframe(filtered_df)
                                                    
                            st.write("### ìµœì¢… ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸")
                            st.code(final_prompt, language="json")

                    else:
                        logging.error(f"âŒ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {filtered_df}")
                        st.error(f"ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {filtered_df}")
                        
                except Exception as e:
                    logging.error(f"ğŸ’¥ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {str(e)}")
                    logging.error(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                    st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    
            else:
                st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()
