{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìƒí’ˆì½”ë“œë³„ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ì‚°ì • ë¶„ì„\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ENTR_BY_INS.csvì™€ ENTR_INT_INS.csv ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒí’ˆì½”ë“œë³„ ìš”ê¸ˆì œ ì •ë³´(ê¸°ë³¸ë£Œ, í‰ìƒí• ì¸, ê¸°ê°„í• ì¸, ì´ë²¤íŠ¸ê°€, ì •ì±…ê¸ˆ)ë¥¼ í™œìš©í•˜ì—¬ ê°€ì… ê³ ê°ì˜ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ì„ ì‚°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ë¶„ì„ ëª©í‘œ\n",
    "- ê°€ì…ì¼ ê¸°ì¤€ M, M+1, M+2... M+nê¹Œì§€ì˜ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
    "- ìƒí’ˆì½”ë“œë³„ ìš”ê¸ˆì œ ì •ì±… ë°˜ì˜\n",
    "- ENTR_BY_INS_FORECASTING.csv, ENTR_INT_INS_FORECASTING.csv íŒŒì¼ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í•œê¸€ í°íŠ¸ ì„¤ì •: Noto Sans Carian\n",
      "ğŸ“Š ìƒí’ˆì½”ë“œë³„ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ì‚°ì • í”„ë¡œê·¸ë¨\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ì°¾ê¸°\n",
    "font_list = [f.name for f in fm.fontManager.ttflist if 'í•œê¸€' in f.name or 'Korean' in f.name or 'Malgun' in f.name or 'Nanum' in f.name or 'Noto' in f.name]\n",
    "\n",
    "if font_list:\n",
    "    plt.rcParams['font.family'] = font_list[0]\n",
    "    print(f\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì •: {font_list[0]}\")\n",
    "else:\n",
    "    # macOSì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ë“¤\n",
    "    mac_fonts = ['AppleGothic', 'Malgun Gothic', 'NanumGothic', 'Noto Sans CJK KR']\n",
    "    for font in mac_fonts:\n",
    "        try:\n",
    "            plt.rcParams['font.family'] = font\n",
    "            print(f\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì •: {font}\")\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "        print(\"âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©\")\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"ğŸ“Š ìƒí’ˆì½”ë“œë³„ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ì‚°ì • í”„ë¡œê·¸ë¨\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "âœ… ENTR_BY_INS.csv ë¡œë“œ ì™„ë£Œ: 270,192í–‰ Ã— 111ì—´\n",
      "âœ… ENTR_INT_INS.csv ë¡œë“œ ì™„ë£Œ: 38,161í–‰ Ã— 106ì—´\n",
      "âœ… MVNO_PRD_PLC.csv ë¡œë“œ ì™„ë£Œ: 138í–‰ Ã— 9ì—´\n",
      "\n",
      "ğŸ“‹ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "print(\"ğŸ“ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "# ENTR_BY_INS.csv ë¡œë“œ (M-2 ì •ì‚°ë‚´ì—­)\n",
    "try:\n",
    "    df_entr_by = pd.read_csv('csv/ENTR_BY_INS.csv', encoding='cp949')\n",
    "    print(f\"âœ… ENTR_BY_INS.csv ë¡œë“œ ì™„ë£Œ: {df_entr_by.shape[0]:,}í–‰ Ã— {df_entr_by.shape[1]}ì—´\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ENTR_BY_INS.csv ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ENTR_INT_INS.csv ë¡œë“œ (M-1 ì‹ ê·œ ê°€ì…ì ì •ë³´)\n",
    "try:\n",
    "    df_entr_int = pd.read_csv('csv/ENTR_INT_INS.csv', encoding='utf-8')\n",
    "    print(f\"âœ… ENTR_INT_INS.csv ë¡œë“œ ì™„ë£Œ: {df_entr_int.shape[0]:,}í–‰ Ã— {df_entr_int.shape[1]}ì—´\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ENTR_INT_INS.csv ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# MVNO_PRD_PLC.csv ë¡œë“œ (ìš”ê¸ˆì œ ì •ë³´)\n",
    "try:\n",
    "    df_plan = pd.read_csv('csv/MVNO_PRD_PLC.csv', encoding='utf-8')\n",
    "    print(f\"âœ… MVNO_PRD_PLC.csv ë¡œë“œ ì™„ë£Œ: {df_plan.shape[0]:,}í–‰ Ã— {df_plan.shape[1]}ì—´\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ MVNO_PRD_PLC.csv ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°ì´í„° ê¸°ë³¸ ì •ë³´\n",
      "==================================================\n",
      "\n",
      "ğŸ” ENTR_BY_INS.csv (M-2 ì •ì‚°ë‚´ì—­):\n",
      "  - ì´ í–‰ ìˆ˜: 270,192\n",
      "  - ì´ ì—´ ìˆ˜: 111\n",
      "  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 462.30 MB\n",
      "\n",
      "ğŸ” ENTR_INT_INS.csv (M-1 ì‹ ê·œ ê°€ì…ì):\n",
      "  - ì´ í–‰ ìˆ˜: 38,161\n",
      "  - ì´ ì—´ ìˆ˜: 106\n",
      "  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 129.72 MB\n",
      "\n",
      "ğŸ” MVNO_PRD_PLC.csv (ìš”ê¸ˆì œ ì •ë³´):\n",
      "  - ì´ í–‰ ìˆ˜: 138\n",
      "  - ì´ ì—´ ìˆ˜: 9\n",
      "  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 0.04 MB\n",
      "\n",
      "ğŸ“‹ ìƒí’ˆì½”ë“œ ê´€ë ¨ ì»¬ëŸ¼:\n",
      "  - ENTR_BY_INS: ['MVNOìƒí’ˆì½”ë“œ', 'MVNOìƒí’ˆëª…', 'ë§ˆì¼“ì½”ë“œ', 'ê°€ì…ëŒ€ë¦¬ì ì½”ë“œ', 'ì‹¤íŒë§¤ì ì½”ë“œ', 'ì •ì‚°ìƒí’ˆì½”ë“œ', 'ì •ì‚°ìƒí’ˆëª…', '83.ë°ì´í„°ì„ êµ¬ë§¤ìƒí’ˆëª…']\n",
      "  - ENTR_INT_INS: ['ìœ ì¹˜ëŒ€ë¦¬ì ì½”ë“œ', 'ìµœì¢…ëŒ€ë¦¬ì ì½”ë“œ', 'ì‹¤íŒë§¤POSì½”ë“œ', 'ì‹¤íŒë§¤POSìœ í˜•ì½”ë“œ', 'ê´€ë¦¬ì ì½”ë“œ', 'ìƒí’ˆë²ˆí˜¸', 'ì„œë¹„ìŠ¤ì½”ë“œ', 'ê°œí†µìš”ê¸ˆì œì½”ë“œ', 'ê°œí†µìš”ê¸ˆì œëª…', 'í˜„ì¬ìš”ê¸ˆì œì½”ë“œ', 'í˜„ì¬ìš”ê¸ˆì œëª…', 'ì›”ë§ìš”ê¸ˆì œì½”ë“œ', 'ì›”ë§ìš”ê¸ˆì œëª…', 'ë‹¨ë§ê¸°êµ¬ë¶„ì½”ë“œ', 'ê°œí†µëª¨ë¸ì½”ë“œ', 'í˜„ì¬ëª¨ë¸ì½”ë“œ', 'ì •ì±…ê¸°ë³€ì½”ë“œ', 'ë¶„ë¦¬í˜•í• ì¸ì½”ë“œ', 'ìƒí’ˆê°œí†µì¼', 'í• ë¶€ìƒíƒœì½”ë“œ', 'í• ë¶€ì²­ì•½ìƒíƒœì½”ë“œ', 'ì‹ ìš©ë“±ê¸‰ì½”ë“œ', 'ë¹„ê³ 1 (ë‹¨ë§ê¸°ì„ì§ì›ì¶”ì²œì½”ë“œ)']\n",
      "  - MVNO_PRD_PLC: ['ìš”ê¸ˆì œì½”ë“œ', 'ìš”ê¸ˆì œëª…']\n",
      "\n",
      "ğŸ“… ë‚ ì§œ ê´€ë ¨ ì»¬ëŸ¼:\n",
      "  - ENTR_BY_INS: ['ìœ íš¨ì‹œì‘ì¼ì', 'ìœ íš¨ì¢…ë£Œì¼ì']\n",
      "  - ENTR_INT_INS: ['ì²˜ë¦¬ì¼ì', 'ê¸°ë³€ì¼ì', 'ì·¨ì†Œì¼ì', 'í•´ì§€ì¼ì', 'ìµœì´ˆê°œí†µì¼ì']\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ê¸°ë³¸ ì •ë³´ í™•ì¸\n",
    "print(\"ğŸ“Š ë°ì´í„° ê¸°ë³¸ ì •ë³´\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nğŸ” ENTR_BY_INS.csv (M-2 ì •ì‚°ë‚´ì—­):\")\n",
    "print(f\"  - ì´ í–‰ ìˆ˜: {df_entr_by.shape[0]:,}\")\n",
    "print(f\"  - ì´ ì—´ ìˆ˜: {df_entr_by.shape[1]}\")\n",
    "print(f\"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df_entr_by.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\nğŸ” ENTR_INT_INS.csv (M-1 ì‹ ê·œ ê°€ì…ì):\")\n",
    "print(f\"  - ì´ í–‰ ìˆ˜: {df_entr_int.shape[0]:,}\")\n",
    "print(f\"  - ì´ ì—´ ìˆ˜: {df_entr_int.shape[1]}\")\n",
    "print(f\"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df_entr_int.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\nğŸ” MVNO_PRD_PLC.csv (ìš”ê¸ˆì œ ì •ë³´):\")\n",
    "print(f\"  - ì´ í–‰ ìˆ˜: {df_plan.shape[0]:,}\")\n",
    "print(f\"  - ì´ ì—´ ìˆ˜: {df_plan.shape[1]}\")\n",
    "print(f\"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df_plan.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# ìƒí’ˆì½”ë“œ ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸\n",
    "print(f\"\\nğŸ“‹ ìƒí’ˆì½”ë“œ ê´€ë ¨ ì»¬ëŸ¼:\")\n",
    "entr_by_product_cols = [col for col in df_entr_by.columns if 'ìƒí’ˆ' in col or 'ì½”ë“œ' in col]\n",
    "print(f\"  - ENTR_BY_INS: {entr_by_product_cols}\")\n",
    "\n",
    "entr_int_product_cols = [col for col in df_entr_int.columns if 'ìƒí’ˆ' in col or 'ì½”ë“œ' in col or 'ìš”ê¸ˆì œ' in col]\n",
    "print(f\"  - ENTR_INT_INS: {entr_int_product_cols}\")\n",
    "\n",
    "plan_product_cols = [col for col in df_plan.columns if 'ìƒí’ˆ' in col or 'ì½”ë“œ' in col or 'ìš”ê¸ˆì œ' in col]\n",
    "print(f\"  - MVNO_PRD_PLC: {plan_product_cols}\")\n",
    "\n",
    "# ë‚ ì§œ ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸\n",
    "print(f\"\\nğŸ“… ë‚ ì§œ ê´€ë ¨ ì»¬ëŸ¼:\")\n",
    "entr_by_date_cols = [col for col in df_entr_by.columns if 'ì¼ì' in col or 'ë‚ ì§œ' in col or 'Date' in col]\n",
    "print(f\"  - ENTR_BY_INS: {entr_by_date_cols}\")\n",
    "\n",
    "entr_int_date_cols = [col for col in df_entr_int.columns if 'ì¼ì' in col or 'ë‚ ì§œ' in col or 'Date' in col]\n",
    "print(f\"  - ENTR_INT_INS: {entr_int_date_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° í•¨ìˆ˜ ì •ì˜\n",
    "def calculate_monthly_forecast(row, months_ahead=12):\n",
    "    \"\"\"\n",
    "    ê°€ì… ê³ ê°ì˜ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Parameters:\n",
    "    - row: ê³ ê° ë°ì´í„° í–‰ (pandas Series)\n",
    "    - months_ahead: ì˜ˆìƒí•  ê°œì›” ìˆ˜ (ê¸°ë³¸ 12ê°œì›”)\n",
    "    \n",
    "    Returns:\n",
    "    - ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ê¸°ë³¸ë£Œ (ì •ì±…ê¸ˆì´ ìˆìœ¼ë©´ ì •ì±…ê¸ˆ, ì—†ìœ¼ë©´ ê¸°ë³¸ë£Œ)\n",
    "        base_fee = row.get('ì •ì±…ê¸ˆ', 0) if pd.notna(row.get('ì •ì±…ê¸ˆ', 0)) and row.get('ì •ì±…ê¸ˆ', 0) > 0 else row.get('ê¸°ë³¸ë£Œ', 0)\n",
    "        \n",
    "        # í• ì¸ ì •ë³´\n",
    "        lifetime_discount = row.get('í‰ìƒí• ì¸', 0) if pd.notna(row.get('í‰ìƒí• ì¸', 0)) else 0\n",
    "        period_discount = row.get('ê¸°ê°„í• ì¸', 0) if pd.notna(row.get('ê¸°ê°„í• ì¸', 0)) else 0\n",
    "        event_fee = row.get('ì´ë²¤íŠ¸ê°€', 0) if pd.notna(row.get('ì´ë²¤íŠ¸ê°€', 0)) else 0\n",
    "        \n",
    "        # ì •ì±… ë°˜ì˜ ê¸°ê°„ í™•ì¸\n",
    "        policy_start = row.get('ì •ì±…ë°˜ì˜ì‹œì‘ì¼', '1900-01-01')\n",
    "        policy_end = row.get('ì •ì±…ë°˜ì˜ì¢…ë£Œì¼', '9999-12-31')\n",
    "        \n",
    "        # ê°€ì…ì¼ (ENTR_BY_INSì˜ ê²½ìš° ì²˜ë¦¬ì¼ì, ENTR_INT_INSì˜ ê²½ìš° ì²˜ë¦¬ì¼ì)\n",
    "        join_date = None\n",
    "        if 'ì²˜ë¦¬ì¼ì' in row.index and pd.notna(row['ì²˜ë¦¬ì¼ì']):\n",
    "            join_date = pd.to_datetime(row['ì²˜ë¦¬ì¼ì'], errors='coerce')\n",
    "        elif 'ê°€ì…ì¼ì' in row.index and pd.notna(row['ê°€ì…ì¼ì']):\n",
    "            join_date = pd.to_datetime(row['ê°€ì…ì¼ì'], errors='coerce')\n",
    "        \n",
    "        if join_date is None or pd.isna(join_date):\n",
    "            return [0] * months_ahead\n",
    "        \n",
    "        # ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
    "        monthly_forecasts = []\n",
    "        \n",
    "        for month in range(months_ahead):\n",
    "            # í•´ë‹¹ ì›”ì˜ ë‚ ì§œ ê³„ì‚°\n",
    "            target_date = join_date + relativedelta(months=month)\n",
    "            \n",
    "            # ì •ì±… ë°˜ì˜ ê¸°ê°„ í™•ì¸\n",
    "            policy_start_date = pd.to_datetime(policy_start, errors='coerce')\n",
    "            policy_end_date = pd.to_datetime(policy_end, errors='coerce')\n",
    "            \n",
    "            # ì •ì±…ì´ ì ìš©ë˜ëŠ” ê¸°ê°„ì¸ì§€ í™•ì¸\n",
    "            is_policy_period = False\n",
    "            if pd.notna(policy_start_date) and pd.notna(policy_end_date):\n",
    "                is_policy_period = policy_start_date <= target_date <= policy_end_date\n",
    "            \n",
    "            # ì›”ë³„ ê¸ˆì•¡ ê³„ì‚°\n",
    "            monthly_amount = base_fee\n",
    "            \n",
    "            # í‰ìƒí• ì¸ ì ìš© (ì •ì±… ê¸°ê°„ì´ê±°ë‚˜ í‰ìƒí• ì¸ì´ ìˆëŠ” ê²½ìš°)\n",
    "            if lifetime_discount > 0 and (is_policy_period or lifetime_discount > 0):\n",
    "                monthly_amount = max(0, monthly_amount - lifetime_discount)\n",
    "            \n",
    "            # ê¸°ê°„í• ì¸ ì ìš© (ì •ì±… ê¸°ê°„ì¸ ê²½ìš°)\n",
    "            if period_discount > 0 and is_policy_period:\n",
    "                monthly_amount = max(0, monthly_amount - period_discount)\n",
    "            \n",
    "            # ì´ë²¤íŠ¸ê°€ ì ìš© (ì •ì±… ê¸°ê°„ì¸ ê²½ìš°)\n",
    "            if event_fee > 0 and is_policy_period:\n",
    "                monthly_amount = max(0, monthly_amount - event_fee)\n",
    "            \n",
    "            monthly_forecasts.append(monthly_amount)\n",
    "        \n",
    "        return monthly_forecasts\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return [0] * months_ahead\n",
    "\n",
    "print(\"âœ… ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— ENTR_BY_INS ë°ì´í„°ì™€ ìš”ê¸ˆì œ ì •ë³´ ë³‘í•©\n",
      "==================================================\n",
      "ğŸ”„ ë°ì´í„° ë³‘í•© ì¤‘...\n",
      "âœ… ENTR_BY_INS ë³‘í•© ì™„ë£Œ: 270,192í–‰ Ã— 120ì—´\n",
      "\n",
      "ğŸ“‹ ë§¤í•‘ ê²°ê³¼:\n",
      "  - ë§¤í•‘ ì„±ê³µ: 270,192ê±´ (100.0%)\n",
      "  - ë§¤í•‘ ì‹¤íŒ¨: 0ê±´ (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# ENTR_BY_INS ë°ì´í„°ì™€ ìš”ê¸ˆì œ ì •ë³´ ë³‘í•©\n",
    "print(\"ğŸ”— ENTR_BY_INS ë°ì´í„°ì™€ ìš”ê¸ˆì œ ì •ë³´ ë³‘í•©\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'MVNOìƒí’ˆì½”ë“œ' in df_entr_by.columns and 'ìš”ê¸ˆì œì½”ë“œ' in df_plan.columns:\n",
    "    # ìš”ê¸ˆì œ ì •ë³´ì™€ ë³‘í•©\n",
    "    print(\"ğŸ”„ ë°ì´í„° ë³‘í•© ì¤‘...\")\n",
    "    merged_entr_by = df_entr_by.merge(\n",
    "        df_plan[['ìš”ê¸ˆì œì½”ë“œ', 'ìš”ê¸ˆì œëª…', 'ê¸°ë³¸ë£Œ', 'í‰ìƒí• ì¸', 'ê¸°ê°„í• ì¸', 'ì´ë²¤íŠ¸ê°€', 'ì •ì±…ê¸ˆ', 'ì •ì±…ë°˜ì˜ì‹œì‘ì¼', 'ì •ì±…ë°˜ì˜ì¢…ë£Œì¼']], \n",
    "        left_on='MVNOìƒí’ˆì½”ë“œ', \n",
    "        right_on='ìš”ê¸ˆì œì½”ë“œ', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… ENTR_BY_INS ë³‘í•© ì™„ë£Œ: {merged_entr_by.shape[0]:,}í–‰ Ã— {merged_entr_by.shape[1]}ì—´\")\n",
    "    \n",
    "    # ë§¤í•‘ ê²°ê³¼ í™•ì¸\n",
    "    matched_count = merged_entr_by['ìš”ê¸ˆì œì½”ë“œ'].notna().sum()\n",
    "    unmatched_count = merged_entr_by['ìš”ê¸ˆì œì½”ë“œ'].isna().sum()\n",
    "    total_count = len(merged_entr_by)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ë§¤í•‘ ê²°ê³¼:\")\n",
    "    print(f\"  - ë§¤í•‘ ì„±ê³µ: {matched_count:,}ê±´ ({matched_count/total_count*100:.1f}%)\")\n",
    "    print(f\"  - ë§¤í•‘ ì‹¤íŒ¨: {unmatched_count:,}ê±´ ({unmatched_count/total_count*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ENTR_BY_INSì™€ ìš”ê¸ˆì œ ì •ë³´ë¥¼ ë³‘í•©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ENTR_BY_INS ì»¬ëŸ¼: {[col for col in df_entr_by.columns if 'ìƒí’ˆ' in col or 'ì½”ë“œ' in col]}\")\n",
    "    print(f\"MVNO_PRD_PLC ì»¬ëŸ¼: {[col for col in df_plan.columns if 'ìƒí’ˆ' in col or 'ì½”ë“œ' in col or 'ìš”ê¸ˆì œ' in col]}\")\n",
    "    merged_entr_by = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”— ENTR_INT_INS ë°ì´í„°ì™€ ìš”ê¸ˆì œ ì •ë³´ ë³‘í•©\n",
      "==================================================\n",
      "ğŸ”„ ë°ì´í„° ë³‘í•© ì¤‘...\n",
      "âœ… ENTR_INT_INS ë³‘í•© ì™„ë£Œ: 38,161í–‰ Ã— 115ì—´\n",
      "\n",
      "ğŸ“‹ ë§¤í•‘ ê²°ê³¼:\n",
      "  - ë§¤í•‘ ì„±ê³µ: 37,959ê±´ (99.5%)\n",
      "  - ë§¤í•‘ ì‹¤íŒ¨: 202ê±´ (0.5%)\n"
     ]
    }
   ],
   "source": [
    "# ENTR_INT_INS ë°ì´í„°ì™€ ìš”ê¸ˆì œ ì •ë³´ ë³‘í•©\n",
    "print(\"\\nğŸ”— ENTR_INT_INS ë°ì´í„°ì™€ ìš”ê¸ˆì œ ì •ë³´ ë³‘í•©\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'ê°œí†µìš”ê¸ˆì œì½”ë“œ' in df_entr_int.columns and 'ìš”ê¸ˆì œì½”ë“œ' in df_plan.columns:\n",
    "    # ìš”ê¸ˆì œ ì •ë³´ì™€ ë³‘í•©\n",
    "    print(\"ğŸ”„ ë°ì´í„° ë³‘í•© ì¤‘...\")\n",
    "    merged_entr_int = df_entr_int.merge(\n",
    "        df_plan[['ìš”ê¸ˆì œì½”ë“œ', 'ìš”ê¸ˆì œëª…', 'ê¸°ë³¸ë£Œ', 'í‰ìƒí• ì¸', 'ê¸°ê°„í• ì¸', 'ì´ë²¤íŠ¸ê°€', 'ì •ì±…ê¸ˆ', 'ì •ì±…ë°˜ì˜ì‹œì‘ì¼', 'ì •ì±…ë°˜ì˜ì¢…ë£Œì¼']], \n",
    "        left_on='ê°œí†µìš”ê¸ˆì œì½”ë“œ', \n",
    "        right_on='ìš”ê¸ˆì œì½”ë“œ', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… ENTR_INT_INS ë³‘í•© ì™„ë£Œ: {merged_entr_int.shape[0]:,}í–‰ Ã— {merged_entr_int.shape[1]}ì—´\")\n",
    "    \n",
    "    # ë§¤í•‘ ê²°ê³¼ í™•ì¸\n",
    "    matched_count = merged_entr_int['ìš”ê¸ˆì œì½”ë“œ'].notna().sum()\n",
    "    unmatched_count = merged_entr_int['ìš”ê¸ˆì œì½”ë“œ'].isna().sum()\n",
    "    total_count = len(merged_entr_int)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ ë§¤í•‘ ê²°ê³¼:\")\n",
    "    print(f\"  - ë§¤í•‘ ì„±ê³µ: {matched_count:,}ê±´ ({matched_count/total_count*100:.1f}%)\")\n",
    "    print(f\"  - ë§¤í•‘ ì‹¤íŒ¨: {unmatched_count:,}ê±´ ({unmatched_count/total_count*100:.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ENTR_INT_INSì™€ ìš”ê¸ˆì œ ì •ë³´ë¥¼ ë³‘í•©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"ENTR_INT_INS ì»¬ëŸ¼: {[col for col in df_entr_int.columns if 'ìƒí’ˆ' in col or 'ì½”ë“œ' in col or 'ìš”ê¸ˆì œ' in col]}\")\n",
    "    print(f\"MVNO_PRD_PLC ì»¬ëŸ¼: {[col for col in df_plan.columns if 'ìƒí’ˆ' in col or 'ì½”ë“œ' in col or 'ìš”ê¸ˆì œ' in col]}\")\n",
    "    merged_entr_int = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ENTR_BY_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
      "==================================================\n",
      "ğŸ”„ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ì¤‘...\n",
      "  - ê³„ì‚° ëŒ€ìƒ: 270,192ê±´\n",
      "âœ… ENTR_BY_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ì™„ë£Œ\n",
      "  - ì´ ê³ ê° ìˆ˜: 270,192ëª…\n",
      "  - ì˜ˆìƒ ê¸°ê°„: 12ê°œì›”\n",
      "\n",
      "ğŸ“‹ ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 5ê°œ):\n",
      "        ê°€ì…ë²ˆí˜¸   MVNOìƒí’ˆì½”ë“œ               ìš”ê¸ˆì œëª…  ê¸°ë³¸ë£Œ  í‰ìƒí• ì¸  ê¸°ê°„í• ì¸  ì´ë²¤íŠ¸ê°€  ì •ì±…ê¸ˆ  M1  M2  M3  M4  M5  M6\n",
      "500224238285 LPZ0002633 [INS]ì¸ìŠ¤ ì„ ë¶ˆì •ì•¡ 300MB    0     0     0     0    0   0   0   0   0   0   0\n",
      "500224410560 LPZ0002633 [INS]ì¸ìŠ¤ ì„ ë¶ˆì •ì•¡ 300MB    0     0     0     0    0   0   0   0   0   0   0\n",
      "500224446685 LPZ0002633 [INS]ì¸ìŠ¤ ì„ ë¶ˆì •ì•¡ 300MB    0     0     0     0    0   0   0   0   0   0   0\n",
      "500224853447 LPZ0002633 [INS]ì¸ìŠ¤ ì„ ë¶ˆì •ì•¡ 300MB    0     0     0     0    0   0   0   0   0   0   0\n",
      "500224979670 LPZ0002633 [INS]ì¸ìŠ¤ ì„ ë¶ˆì •ì•¡ 300MB    0     0     0     0    0   0   0   0   0   0   0\n",
      "\n",
      "ğŸ“ˆ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ í†µê³„:\n",
      "  - M1: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M2: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M3: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M4: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M5: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M6: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M7: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M8: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M9: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M10: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M11: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M12: ì´ 0ì›, í‰ê·  0ì›\n"
     ]
    }
   ],
   "source": [
    "# ENTR_BY_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
    "print(\"\\nğŸ“Š ENTR_BY_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if merged_entr_by is not None:\n",
    "    print(\"ğŸ”„ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ì¤‘...\")\n",
    "    \n",
    "    # ë§¤í•‘ëœ ë°ì´í„°ë§Œ ì‚¬ìš©\n",
    "    matched_data = merged_entr_by[merged_entr_by['ìš”ê¸ˆì œì½”ë“œ'].notna()].copy()\n",
    "    print(f\"  - ê³„ì‚° ëŒ€ìƒ: {len(matched_data):,}ê±´\")\n",
    "    \n",
    "    # ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° (12ê°œì›”)\n",
    "    months_ahead = 12\n",
    "    forecast_columns = [f'M{month+1}' for month in range(months_ahead)]\n",
    "    \n",
    "    # ê° ê³ ê°ì— ëŒ€í•´ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
    "    forecasts = []\n",
    "    for idx, row in matched_data.iterrows():\n",
    "        monthly_forecast = calculate_monthly_forecast(row, months_ahead)\n",
    "        forecasts.append(monthly_forecast)\n",
    "    \n",
    "    # ì˜ˆìƒ ê¸ˆì•¡ì„ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€\n",
    "    forecast_df = pd.DataFrame(forecasts, columns=forecast_columns, index=matched_data.index)\n",
    "    \n",
    "    # ì›ë³¸ ë°ì´í„°ì™€ ì˜ˆìƒ ê¸ˆì•¡ ë°ì´í„° ê²°í•©\n",
    "    entr_by_forecast = matched_data.copy()\n",
    "    for col in forecast_columns:\n",
    "        entr_by_forecast[col] = forecast_df[col]\n",
    "    \n",
    "    print(f\"âœ… ENTR_BY_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ì™„ë£Œ\")\n",
    "    print(f\"  - ì´ ê³ ê° ìˆ˜: {len(entr_by_forecast):,}ëª…\")\n",
    "    print(f\"  - ì˜ˆìƒ ê¸°ê°„: {months_ahead}ê°œì›”\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
    "    print(f\"\\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 5ê°œ):\")\n",
    "    sample_cols = ['ê°€ì…ë²ˆí˜¸', 'MVNOìƒí’ˆì½”ë“œ', 'ìš”ê¸ˆì œëª…', 'ê¸°ë³¸ë£Œ', 'í‰ìƒí• ì¸', 'ê¸°ê°„í• ì¸', 'ì´ë²¤íŠ¸ê°€', 'ì •ì±…ê¸ˆ'] + forecast_columns[:6]\n",
    "    available_sample_cols = [col for col in sample_cols if col in entr_by_forecast.columns]\n",
    "    print(entr_by_forecast[available_sample_cols].head().to_string(index=False))\n",
    "    \n",
    "    # ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ í†µê³„\n",
    "    print(f\"\\nğŸ“ˆ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ í†µê³„:\")\n",
    "    for col in forecast_columns:\n",
    "        total_amount = entr_by_forecast[col].sum()\n",
    "        avg_amount = entr_by_forecast[col].mean()\n",
    "        print(f\"  - {col}: ì´ {total_amount:,.0f}ì›, í‰ê·  {avg_amount:,.0f}ì›\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ENTR_BY_INS ë³‘í•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ENTR_INT_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
      "==================================================\n",
      "ğŸ”„ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ì¤‘...\n",
      "  - ê³„ì‚° ëŒ€ìƒ: 37,959ê±´\n",
      "âœ… ENTR_INT_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ì™„ë£Œ\n",
      "  - ì´ ê³ ê° ìˆ˜: 37,959ëª…\n",
      "  - ì˜ˆìƒ ê¸°ê°„: 12ê°œì›”\n",
      "\n",
      "ğŸ“‹ ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 5ê°œ):\n",
      "        ê°€ì…ë²ˆí˜¸    ê°œí†µìš”ê¸ˆì œì½”ë“œ                     ìš”ê¸ˆì œëª…  ê¸°ë³¸ë£Œ  í‰ìƒí• ì¸  ê¸°ê°„í• ì¸  ì´ë²¤íŠ¸ê°€  ì •ì±…ê¸ˆ  M1  M2  M3  M4  M5  M6\n",
      "514438614667 LPZ0002642          [INS]ì¸ìŠ¤ LTEì„ ë¶ˆí‘œì¤€  0.0   0.0   0.0   0.0  0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "516962662784 LPZ0002642          [INS]ì¸ìŠ¤ LTEì„ ë¶ˆí‘œì¤€  0.0   0.0   0.0   0.0  0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "513292045339 LPZ0002633       [INS]ì¸ìŠ¤ ì„ ë¶ˆì •ì•¡ 300MB  0.0   0.0   0.0   0.0  0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "517165546050 LPZ0002639        [INS]ì¸ìŠ¤ ì •ì•¡ì„ ë¶ˆ 11G+  0.0   0.0   0.0   0.0  0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "515622799160 LPZ0002644 [INS]ì¸ìŠ¤ ì„ ë¶ˆì •ì•¡ 300MB+1Mbps  0.0   0.0   0.0   0.0  0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      "\n",
      "ğŸ“ˆ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ í†µê³„:\n",
      "  - M1: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M2: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M3: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M4: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M5: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M6: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M7: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M8: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M9: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M10: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M11: ì´ 0ì›, í‰ê·  0ì›\n",
      "  - M12: ì´ 0ì›, í‰ê·  0ì›\n"
     ]
    }
   ],
   "source": [
    "# ENTR_INT_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
    "print(\"\\nğŸ“Š ENTR_INT_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if merged_entr_int is not None:\n",
    "    print(\"ğŸ”„ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ì¤‘...\")\n",
    "    \n",
    "    # ë§¤í•‘ëœ ë°ì´í„°ë§Œ ì‚¬ìš©\n",
    "    matched_data = merged_entr_int[merged_entr_int['ìš”ê¸ˆì œì½”ë“œ'].notna()].copy()\n",
    "    print(f\"  - ê³„ì‚° ëŒ€ìƒ: {len(matched_data):,}ê±´\")\n",
    "    \n",
    "    # ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° (12ê°œì›”)\n",
    "    months_ahead = 12\n",
    "    forecast_columns = [f'M{month+1}' for month in range(months_ahead)]\n",
    "    \n",
    "    # ê° ê³ ê°ì— ëŒ€í•´ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
    "    forecasts = []\n",
    "    for idx, row in matched_data.iterrows():\n",
    "        monthly_forecast = calculate_monthly_forecast(row, months_ahead)\n",
    "        forecasts.append(monthly_forecast)\n",
    "    \n",
    "    # ì˜ˆìƒ ê¸ˆì•¡ì„ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€\n",
    "    forecast_df = pd.DataFrame(forecasts, columns=forecast_columns, index=matched_data.index)\n",
    "    \n",
    "    # ì›ë³¸ ë°ì´í„°ì™€ ì˜ˆìƒ ê¸ˆì•¡ ë°ì´í„° ê²°í•©\n",
    "    entr_int_forecast = matched_data.copy()\n",
    "    for col in forecast_columns:\n",
    "        entr_int_forecast[col] = forecast_df[col]\n",
    "    \n",
    "    print(f\"âœ… ENTR_INT_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ì™„ë£Œ\")\n",
    "    print(f\"  - ì´ ê³ ê° ìˆ˜: {len(entr_int_forecast):,}ëª…\")\n",
    "    print(f\"  - ì˜ˆìƒ ê¸°ê°„: {months_ahead}ê°œì›”\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë°ì´í„° í™•ì¸\n",
    "    print(f\"\\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 5ê°œ):\")\n",
    "    sample_cols = ['ê°€ì…ë²ˆí˜¸', 'ê°œí†µìš”ê¸ˆì œì½”ë“œ', 'ìš”ê¸ˆì œëª…', 'ê¸°ë³¸ë£Œ', 'í‰ìƒí• ì¸', 'ê¸°ê°„í• ì¸', 'ì´ë²¤íŠ¸ê°€', 'ì •ì±…ê¸ˆ'] + forecast_columns[:6]\n",
    "    available_sample_cols = [col for col in sample_cols if col in entr_int_forecast.columns]\n",
    "    print(entr_int_forecast[available_sample_cols].head().to_string(index=False))\n",
    "    \n",
    "    # ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ í†µê³„\n",
    "    print(f\"\\nğŸ“ˆ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ í†µê³„:\")\n",
    "    for col in forecast_columns:\n",
    "        total_amount = entr_int_forecast[col].sum()\n",
    "        avg_amount = entr_int_forecast[col].mean()\n",
    "        print(f\"  - {col}: ì´ {total_amount:,.0f}ì›, í‰ê·  {avg_amount:,.0f}ì›\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ENTR_INT_INS ë³‘í•© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ì‹œê°í™”\n",
    "print(\"\\nğŸ“Š ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ì‹œê°í™”\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'entr_by_forecast' in locals() and 'entr_int_forecast' in locals():\n",
    "    # ì›”ë³„ ì´ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
    "    entr_by_monthly_totals = []\n",
    "    entr_int_monthly_totals = []\n",
    "    \n",
    "    for col in forecast_columns:\n",
    "        entr_by_monthly_totals.append(entr_by_forecast[col].sum())\n",
    "        entr_int_monthly_totals.append(entr_int_forecast[col].sum())\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. ì›”ë³„ ì´ ì˜ˆìƒ ê¸ˆì•¡ ë¹„êµ\n",
    "    plt.subplot(2, 2, 1)\n",
    "    months = [f'M{i+1}' for i in range(len(forecast_columns))]\n",
    "    plt.plot(months, entr_by_monthly_totals, marker='o', label='ENTR_BY_INS', linewidth=2)\n",
    "    plt.plot(months, entr_int_monthly_totals, marker='s', label='ENTR_INT_INS', linewidth=2)\n",
    "    plt.title('ì›”ë³„ ì´ ì˜ˆìƒ ê¸ˆì•¡ ë¹„êµ', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('ì›”')\n",
    "    plt.ylabel('ì´ ì˜ˆìƒ ê¸ˆì•¡ (ì›)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 2. ì›”ë³„ í‰ê·  ì˜ˆìƒ ê¸ˆì•¡ ë¹„êµ\n",
    "    plt.subplot(2, 2, 2)\n",
    "    entr_by_avg = [entr_by_forecast[col].mean() for col in forecast_columns]\n",
    "    entr_int_avg = [entr_int_forecast[col].mean() for col in forecast_columns]\n",
    "    plt.plot(months, entr_by_avg, marker='o', label='ENTR_BY_INS', linewidth=2)\n",
    "    plt.plot(months, entr_int_avg, marker='s', label='ENTR_INT_INS', linewidth=2)\n",
    "    plt.title('ì›”ë³„ í‰ê·  ì˜ˆìƒ ê¸ˆì•¡ ë¹„êµ', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('ì›”')\n",
    "    plt.ylabel('í‰ê·  ì˜ˆìƒ ê¸ˆì•¡ (ì›)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 3. ìš”ê¸ˆì œë³„ ì˜ˆìƒ ê¸ˆì•¡ ë¶„í¬ (ENTR_BY_INS)\n",
    "    plt.subplot(2, 2, 3)\n",
    "    if 'ìš”ê¸ˆì œëª…' in entr_by_forecast.columns:\n",
    "        top_plans = entr_by_forecast['ìš”ê¸ˆì œëª…'].value_counts().head(10)\n",
    "        plan_totals = []\n",
    "        for plan in top_plans.index:\n",
    "            plan_data = entr_by_forecast[entr_by_forecast['ìš”ê¸ˆì œëª…'] == plan]\n",
    "            plan_total = plan_data[forecast_columns].sum().sum()\n",
    "            plan_totals.append(plan_total)\n",
    "        \n",
    "        plt.barh(range(len(top_plans)), plan_totals, color='skyblue', alpha=0.7)\n",
    "        plt.title('ìƒìœ„ 10ê°œ ìš”ê¸ˆì œë³„ ì´ ì˜ˆìƒ ê¸ˆì•¡ (ENTR_BY_INS)', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('ì´ ì˜ˆìƒ ê¸ˆì•¡ (ì›)')\n",
    "        plt.yticks(range(len(top_plans)), [plan[:20] + '...' if len(plan) > 20 else plan for plan in top_plans.index])\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. ìš”ê¸ˆì œë³„ ì˜ˆìƒ ê¸ˆì•¡ ë¶„í¬ (ENTR_INT_INS)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    if 'ìš”ê¸ˆì œëª…' in entr_int_forecast.columns:\n",
    "        top_plans = entr_int_forecast['ìš”ê¸ˆì œëª…'].value_counts().head(10)\n",
    "        plan_totals = []\n",
    "        for plan in top_plans.index:\n",
    "            plan_data = entr_int_forecast[entr_int_forecast['ìš”ê¸ˆì œëª…'] == plan]\n",
    "            plan_total = plan_data[forecast_columns].sum().sum()\n",
    "            plan_totals.append(plan_total)\n",
    "        \n",
    "        plt.barh(range(len(top_plans)), plan_totals, color='lightcoral', alpha=0.7)\n",
    "        plt.title('ìƒìœ„ 10ê°œ ìš”ê¸ˆì œë³„ ì´ ì˜ˆìƒ ê¸ˆì•¡ (ENTR_INT_INS)', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('ì´ ì˜ˆìƒ ê¸ˆì•¡ (ì›)')\n",
    "        plt.yticks(range(len(top_plans)), [plan[:20] + '...' if len(plan) > 20 else plan for plan in top_plans.index])\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… ì‹œê°í™” ì™„ë£Œ!\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ì˜ˆìƒ ê¸ˆì•¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "print(\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # ENTR_BY_INS_FORECASTING.csv ì €ì¥\n",
    "    if 'entr_by_forecast' in locals():\n",
    "        entr_by_forecast.to_csv('ENTR_BY_INS_FORECASTING.csv', index=False, encoding='utf-8')\n",
    "        print(\"âœ… ENTR_BY_INS_FORECASTING.csv ì €ì¥ ì™„ë£Œ\")\n",
    "        \n",
    "        # ì €ì¥ëœ íŒŒì¼ ì •ë³´\n",
    "        import os\n",
    "        file_size = os.path.getsize('ENTR_BY_INS_FORECASTING.csv') / (1024 * 1024)  # MB\n",
    "        print(f\"ğŸ“ ENTR_BY_INS_FORECASTING.csv íŒŒì¼ ì •ë³´:\")\n",
    "        print(f\"  - í¬ê¸°: {file_size:.2f} MB\")\n",
    "        print(f\"  - í–‰ ìˆ˜: {entr_by_forecast.shape[0]:,}\")\n",
    "        print(f\"  - ì—´ ìˆ˜: {entr_by_forecast.shape[1]}\")\n",
    "    \n",
    "    # ENTR_INT_INS_FORECASTING.csv ì €ì¥\n",
    "    if 'entr_int_forecast' in locals():\n",
    "        entr_int_forecast.to_csv('ENTR_INT_INS_FORECASTING.csv', index=False, encoding='utf-8')\n",
    "        print(\"âœ… ENTR_INT_INS_FORECASTING.csv ì €ì¥ ì™„ë£Œ\")\n",
    "        \n",
    "        # ì €ì¥ëœ íŒŒì¼ ì •ë³´\n",
    "        file_size = os.path.getsize('ENTR_INT_INS_FORECASTING.csv') / (1024 * 1024)  # MB\n",
    "        print(f\"ğŸ“ ENTR_INT_INS_FORECASTING.csv íŒŒì¼ ì •ë³´:\")\n",
    "        print(f\"  - í¬ê¸°: {file_size:.2f} MB\")\n",
    "        print(f\"  - í–‰ ìˆ˜: {entr_int_forecast.shape[0]:,}\")\n",
    "        print(f\"  - ì—´ ìˆ˜: {entr_int_forecast.shape[1]}\")\n",
    "    \n",
    "    # ìš”ì•½ í†µê³„ ì €ì¥\n",
    "    if 'entr_by_forecast' in locals() and 'entr_int_forecast' in locals():\n",
    "        summary_data = {\n",
    "            'êµ¬ë¶„': ['ENTR_BY_INS', 'ENTR_INT_INS'],\n",
    "            'ì´_ê³ ê°ìˆ˜': [len(entr_by_forecast), len(entr_int_forecast)],\n",
    "            '12ê°œì›”_ì´ì˜ˆìƒê¸ˆì•¡': [\n",
    "                entr_by_forecast[forecast_columns].sum().sum(),\n",
    "                entr_int_forecast[forecast_columns].sum().sum()\n",
    "            ],\n",
    "            '12ê°œì›”_í‰ê· ì˜ˆìƒê¸ˆì•¡': [\n",
    "                entr_by_forecast[forecast_columns].mean().mean(),\n",
    "                entr_int_forecast[forecast_columns].mean().mean()\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_csv('FORECASTING_SUMMARY.csv', index=False, encoding='utf-8')\n",
    "        print(\"âœ… FORECASTING_SUMMARY.csv ì €ì¥ ì™„ë£Œ\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ìš”ì•½ í†µê³„:\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "    \n",
    "    print(f\"\\nğŸ“ ì €ì¥ëœ íŒŒì¼:\")\n",
    "    if 'entr_by_forecast' in locals():\n",
    "        print(f\"  - ENTR_BY_INS_FORECASTING.csv: ENTR_BY_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡\")\n",
    "    if 'entr_int_forecast' in locals():\n",
    "        print(f\"  - ENTR_INT_INS_FORECASTING.csv: ENTR_INT_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡\")\n",
    "    if 'summary_df' in locals():\n",
    "        print(f\"  - FORECASTING_SUMMARY.csv: ì˜ˆìƒ ê¸ˆì•¡ ìš”ì•½ í†µê³„\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ì‚°ì • ë¶„ì„ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ ë‹¤ìŒê³¼ ê°™ì€ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **ë°ì´í„° ë¡œë“œ**: ENTR_BY_INS.csv, ENTR_INT_INS.csv, MVNO_PRD_PLC.csv íŒŒì¼ ë¡œë“œ\n",
    "2. **ìš”ê¸ˆì œ ì •ë³´ ë³‘í•©**: ìƒí’ˆì½”ë“œì™€ ìš”ê¸ˆì œ ì •ë³´ ì—°ê²°\n",
    "3. **ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°**: ê°€ì…ì¼ ê¸°ì¤€ M, M+1, M+2... M+12ê¹Œì§€ì˜ ì˜ˆìƒ ê¸ˆì•¡ ì‚°ì •\n",
    "4. **ìš”ê¸ˆì œ ì •ì±… ë°˜ì˜**: ê¸°ë³¸ë£Œ, í‰ìƒí• ì¸, ê¸°ê°„í• ì¸, ì´ë²¤íŠ¸ê°€, ì •ì±…ê¸ˆ, ì •ì±…ë°˜ì˜ê¸°ê°„ ì ìš©\n",
    "5. **ì‹œê°í™”**: ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ íŠ¸ë Œë“œ ë° ìš”ê¸ˆì œë³„ ë¶„í¬ ë¶„ì„\n",
    "6. **ê²°ê³¼ ì €ì¥**: ì˜ˆìƒ ê¸ˆì•¡ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "\n",
    "### ì£¼ìš” ì¶œë ¥ íŒŒì¼:\n",
    "- `ENTR_BY_INS_FORECASTING.csv`: ENTR_BY_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ (M1~M12)\n",
    "- `ENTR_INT_INS_FORECASTING.csv`: ENTR_INT_INS ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ (M1~M12)\n",
    "- `FORECASTING_SUMMARY.csv`: ì˜ˆìƒ ê¸ˆì•¡ ìš”ì•½ í†µê³„\n",
    "\n",
    "### ğŸ” ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚° ë¡œì§:\n",
    "- **ê¸°ë³¸ë£Œ**: ì •ì±…ê¸ˆì´ ìˆìœ¼ë©´ ì •ì±…ê¸ˆ, ì—†ìœ¼ë©´ ê¸°ë³¸ë£Œ ì‚¬ìš©\n",
    "- **í‰ìƒí• ì¸**: ì •ì±… ê¸°ê°„ì´ê±°ë‚˜ í‰ìƒí• ì¸ì´ ìˆëŠ” ê²½ìš° ì ìš©\n",
    "- **ê¸°ê°„í• ì¸**: ì •ì±… ê¸°ê°„ì¸ ê²½ìš°ì—ë§Œ ì ìš©\n",
    "- **ì´ë²¤íŠ¸ê°€**: ì •ì±… ê¸°ê°„ì¸ ê²½ìš°ì—ë§Œ ì ìš©\n",
    "- **ì •ì±…ë°˜ì˜ê¸°ê°„**: ì •ì±…ë°˜ì˜ì‹œì‘ì¼~ì •ì±…ë°˜ì˜ì¢…ë£Œì¼ ë²”ìœ„ ë‚´ì—ì„œë§Œ í• ì¸ ì ìš©\n",
    "\n",
    "### ğŸ“ˆ ë¶„ì„ íŠ¹ì§•:\n",
    "- **ê°€ì…ì¼ ê¸°ì¤€**: ê° ê³ ê°ì˜ ê°€ì…ì¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ê³„ì‚°\n",
    "- **ì •ì±… ë°˜ì˜**: ìš”ê¸ˆì œë³„ ì •ì±… ë°˜ì˜ ê¸°ê°„ì„ ê³ ë ¤í•œ ë™ì  í• ì¸ ì ìš©\n",
    "- **12ê°œì›” ì˜ˆì¸¡**: ê°€ì… í›„ 12ê°œì›”ê°„ì˜ ì›”ë³„ ì˜ˆìƒ ê¸ˆì•¡ ì œê³µ\n",
    "- **ìš”ê¸ˆì œë³„ ë¶„ì„**: ìƒí’ˆì½”ë“œë³„ ìš”ê¸ˆì œ ì •ì±…ì— ë”°ë¥¸ ì°¨ë³„í™”ëœ ì˜ˆìƒ ê¸ˆì•¡\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
